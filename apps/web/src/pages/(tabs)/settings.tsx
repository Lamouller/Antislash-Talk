import { useState, useEffect } from 'react';
import { supabase } from '../../lib/supabase';
import { useNavigate } from 'react-router-dom';
import { Button } from '../../components/ui/Button';
import { Card } from '../../components/ui/Card';
import { ApiKey } from '../../lib/schemas';
import toast from 'react-hot-toast';
import { useLocalTranscription } from '../../hooks/useLocalTranscription';
import { useOllama } from '../../hooks/useOllama';
import { useLicense } from '../../lib/licensing';
import { FeatureGate, FeatureComparison } from '../../components/ui/FeatureGate';
import { Settings, Server as ServerIcon, Globe as GlobeIcon } from 'lucide-react';
import { checkWhisperXAvailability } from '../../lib/whisperx-client';

type LlmProvider = 'openai' | 'anthropic' | 'google' | 'mistral';
type SttTtsProvider = 'openai' | 'google' | 'mistral' | 'local';

interface Model {
  id: string;
  name: string;
  description: string;
  size?: string;
  languages?: string;
  requiresServer?: boolean;
  supportsDiarization?: boolean;
}

const llmModels: Record<LlmProvider, Model[]> = {
  openai: [
    {
      id: 'gpt-4o',
      name: 'GPT-4o',
      description: 'Latest flagship model from OpenAI.',
    },
    {
      id: 'gpt-4o-mini',
      name: 'GPT-4o mini',
      description: 'Affordable, intelligent small model.',
    },
  ],
  anthropic: [
    {
      id: 'claude-3-5-sonnet-20241022',
      name: 'Claude 3.5 Sonnet',
      description: 'Most intelligent model.',
    },
    {
      id: 'claude-3-5-haiku-20241022',
      name: 'Claude 3.5 Haiku',
      description: 'Fastest model.',
    },
  ],
  google: [
    {
      id: 'gemini-2.0-flash-exp',
      name: 'Gemini 2.0 Flash ‚ö° NEW',
      description: 'Latest experimental model. Fastest with multimodal capabilities.',
    },
    {
      id: 'gemini-1.5-pro',
      name: 'Gemini 1.5 Pro',
      description: 'Most capable model for complex reasoning tasks.',
    },
    {
      id: 'gemini-1.5-flash',
      name: 'Gemini 1.5 Flash',
      description: 'Fast and cost-effective for diverse tasks.',
    },
    {
      id: 'gemini-1.5-flash-8b',
      name: 'Gemini 1.5 Flash-8B',
      description: 'Smallest, fastest model for simple tasks.',
    },
  ],
  mistral: [
    {
      id: 'mistral-large-latest',
      name: 'Mistral Large',
      description: 'Top-tier reasoning for high-complexity tasks.',
    },
    {
      id: 'mistral-small-latest',
      name: 'Mistral Small',
      description: 'Cost-efficient reasoning for simple tasks.',
    },
  ],
};

const transcriptionModels: Record<SttTtsProvider, Model[]> = {
  openai: [
    {
      id: 'whisper-1',
      name: 'Whisper',
      description: 'Powerful speech-to-text model.',
    },
  ],
  google: [
    {
      id: 'gemini-2.0-flash-exp',
      name: 'Gemini 2.0 Flash ‚ö° NEW',
      description: 'Latest model with native audio understanding.',
    },
    {
      id: 'gemini-1.5-pro',
      name: 'Gemini 1.5 Pro',
      description: 'High-quality transcription with best accuracy.',
    },
    {
      id: 'gemini-1.5-flash',
      name: 'Gemini 1.5 Flash',
      description: 'Fast transcription with good balance.',
    },
    {
      id: 'gemini-1.5-flash-8b',
      name: 'Gemini 1.5 Flash-8B',
      description: 'Fastest, most cost-effective option.',
    },
  ],
  mistral: [
    {
      id: 'voxtral-small',
      name: 'Voxtral Small üéØ ‚ö°',
      description: 'Revolutionary multimodal model with superior transcription, Q&A, and semantic understanding. Best quality option.',
    },
    {
      id: 'voxtral-mini',
      name: 'Voxtral Mini üí®',
      description: 'Lightweight version of Voxtral with fast transcription and built-in understanding capabilities.',
    },
  ],
  local: [
    {
      id: 'Xenova/whisper-tiny',
      name: 'Tiny ‚ö°',
      description: 'Ultra-rapide (whisper.cpp). Pas de diarization.',
      size: '39MB',
      languages: '99 languages'
    },
    {
      id: 'Xenova/whisper-tiny+diarization',
      name: 'Tiny + Diarization üé≠ LIVE',
      description: 'Ultra-rapide avec identification des locuteurs. Parfait pour streaming live.',
      size: '39MB + 2.88GB',
      languages: '99 languages',
      requiresServer: false,
      supportsDiarization: true
    },
    {
      id: 'Xenova/whisper-base',
      name: 'Base ‚≠ê',
      description: 'Meilleur compromis vitesse/qualit√© (whisper.cpp).',
      size: '74MB',
      languages: '99 languages'
    },
    {
      id: 'Xenova/whisper-base+diarization',
      name: 'Base + Diarization üé≠',
      description: 'Bon compromis avec identification des locuteurs.',
      size: '74MB + 2.88GB',
      languages: '99 languages',
      requiresServer: false,
      supportsDiarization: true
    },
    {
      id: 'onnx-community/moonshine-tiny-ONNX',
      name: 'Moonshine Tiny',
      description: 'Alternative ultra-compacte. Anglais uniquement.',
      size: '50MB',
      languages: 'English only'
    },
    {
      id: 'onnx-community/moonshine-base-ONNX',
      name: 'Moonshine Base',
      description: 'Alternative plus pr√©cise. Anglais uniquement.',
      size: '125MB',
      languages: 'English only'
    },
    {
      id: 'Xenova/whisper-small',
      name: 'Small',
      description: 'Qualit√© sup√©rieure.',
      size: '244MB',
      languages: '99 languages'
    },
    {
      id: 'Xenova/whisper-small.fr',
      name: 'Small FR üá´üá∑',
      description: 'Optimis√© fran√ßais.',
      size: '244MB',
      languages: 'French + multilingual'
    },
    {
      id: 'distil-whisper/distil-large-v3',
      name: 'Large Distill√© üá´üá∑',
      description: 'Haute qualit√© avec identification des locuteurs.',
      size: '756MB',
      languages: 'French + 99 languages',
      requiresServer: true,
      supportsDiarization: true
    },
    {
      id: 'Xenova/whisper-medium',
      name: 'Medium',
      description: 'Haute qualit√© multilangue.',
      size: '769MB',
      languages: '99 languages',
      requiresServer: true
    },
    {
      id: 'Xenova/whisper-medium+diarization',
      name: 'Medium + Diarization',
      description: 'Identification des locuteurs.',
      size: '769MB + 2.88GB',
      languages: '99 languages',
      requiresServer: true,
      supportsDiarization: true
    },
    {
      id: 'Xenova/whisper-large-v2',
      name: 'Large v2',
      description: 'Pr√©cision maximale.',
      size: '1.5GB',
      languages: '99 languages',
      requiresServer: true
    },
    {
      id: 'openai/whisper-large-v3',
      name: 'Large v3 + Diarization üèÜ',
      description: 'Meilleur mod√®le avec identification des locuteurs.',
      size: '1.5GB',
      languages: '99 languages',
      requiresServer: true,
      supportsDiarization: true
    },
    {
      id: 'bofenghuang/whisper-large-v2-french',
      name: 'Large FR üá´üá∑',
      description: 'Sp√©cialis√© fran√ßais.',
      size: '1.5GB',
      languages: 'French specialist',
      requiresServer: true
    }
  ]
};

const ttsModels: Record<SttTtsProvider, Model[]> = {
  openai: [
    { id: 'tts-1', name: 'TTS-1', description: 'Optimized for real-time.' },
    { id: 'tts-1-hd', name: 'TTS-1-HD', description: 'Optimized for quality.' },
  ],
  google: [ 
    { id: 'gemini-2.0-flash-exp', name: 'Gemini 2.0 Flash TTS', description: 'Native multimodal audio generation.' },
    { id: 'gemini-1.5-flash', name: 'Gemini 1.5 Flash TTS', description: 'Reliable text-to-speech generation.' },
  ],
  mistral: [
    { 
      id: 'mistral-tts', 
      name: 'Mistral TTS (Coming Soon)', 
      description: 'Advanced text-to-speech from Mistral AI. Currently not available.'
    }
  ],
  local: [
    { 
      id: 'browser-tts', 
      name: 'Browser TTS', 
      description: 'Uses your device\'s built-in text-to-speech. No internet required.',
      size: 'Built-in',
      languages: 'Multiple languages (device dependent)'
    }
  ]
};

// Ollama LLM Models (for local title/summary generation)
// Sorted by RAM usage (lightweight first)
const ollamaModels: Model[] = [
  {
    id: 'none',
    name: 'üö´ None (Rule-based)',
    description: 'Simple rule-based title and summary generation. Fast but less intelligent.',
    size: '0 MB',
    languages: 'All languages'
  },
  {
    id: 'phi3:mini',
    name: 'Phi-3 Mini ‚ö° RECOMMENDED',
    description: 'Ultra-fast lightweight model from Microsoft. Best for low-RAM systems. Good French support.',
    size: '2.3 GB',
    languages: 'English, French'
  },
  {
    id: 'gemma2:2b',
    name: 'Gemma 2 2B ü™∂ ULTRA-LIGHT',
    description: 'Smallest model from Google. Perfect for very limited RAM (< 3 GB available).',
    size: '1.6 GB',
    languages: 'Multilingual'
  },
  {
    id: 'llama3.2:latest',
    name: 'Llama 3.2 ü¶ô NEW',
    description: 'Latest Llama model from Meta. Balanced performance and quality. Good for general use.',
    size: '2 GB',
    languages: 'Multilingual, excellent French support'
  },
  {
    id: 'qwen2.5:3b',
    name: 'Qwen 2.5 3B üöÄ FAST',
    description: 'Fast Chinese model with good multilingual support. Excellent speed/quality ratio.',
    size: '2 GB',
    languages: 'Multilingual (Chinese, English, French)'
  },
  {
    id: 'mistral',
    name: 'Mistral 7B üá´üá∑',
    description: 'Excellent for French. Requires ~5 GB RAM. Best quality for systems with enough memory.',
    size: '4 GB',
    languages: 'French, English, multilingual'
  },
  {
    id: 'llama3.1:8b',
    name: 'Llama 3.1 8B üèÜ',
    description: 'State-of-the-art model from Meta. Requires ~5-6 GB RAM. Top quality for powerful systems.',
    size: '5 GB',
    languages: 'Multilingual, excellent French support'
  },
  {
    id: 'gemma2:9b',
    name: 'Gemma 2 9B üá´üá∑',
    description: 'Excellent French support. Requires ~6 GB RAM. Great for detailed analysis.',
    size: '5.5 GB',
    languages: 'Multilingual, strong French performance'
  },
  {
    id: 'qwen2.5:7b',
    name: 'Qwen 2.5 7B üéØ QUALITY',
    description: 'Larger Qwen model with excellent quality. Good balance between speed and accuracy.',
    size: '4.7 GB',
    languages: 'Multilingual (Chinese, English, French)'
  }
];

export default function SettingsScreen() {
  const navigate = useNavigate();
  const { runBenchmark, benchmark } = useLocalTranscription();
  const { pullModel } = useOllama();
  const [loading, setLoading] = useState(true);
  const [isBenchmarking, setIsBenchmarking] = useState(false);
  const [apiKeys, setApiKeys] = useState<Partial<ApiKey>[]>([]);
  const [hasChanges, setHasChanges] = useState(false);
  const [downloadingModel, setDownloadingModel] = useState(false);
  
  // Ollama status
  const [ollamaStatus, setOllamaStatus] = useState<{
    available: boolean;
    models: string[];
    checking: boolean;
  }>({ available: false, models: [], checking: false });
  
  // PyTorch status
  const [pytorchStatus, setPytorchStatus] = useState<{
    available: boolean;
    diarization: boolean;
    checking: boolean;
  }>({ available: false, diarization: false, checking: false });
  
  // WhisperX status
  const [whisperXStatus, setWhisperXStatus] = useState<{
    available: boolean;
    diarization: boolean;
    checking: boolean;
    device: string;
  }>({ available: false, diarization: false, checking: false, device: 'cpu' });

  // Pyannote models status
  const [pyannoteModels, setPyannoteModels] = useState<Array<{
    id: string;
    name: string;
    size: string;
    description: string;
    required: boolean;
    main: boolean;
    downloaded: boolean;
  }>>([]);
  const [downloadingPyannote, setDownloadingPyannote] = useState(false);

  // LLM State
  const [selectedLlmProvider, setSelectedLlmProvider] = useState<LlmProvider>('openai');
  const [selectedLlmModel, setSelectedLlmModel] = useState<string | null>(null);

  // Transcription State
  const [preferredTranscriptionProvider, setPreferredTranscriptionProvider] = useState<SttTtsProvider>('openai');
  const [preferredTranscriptionModel, setPreferredTranscriptionModel] = useState<string | null>(null);
  
  // TTS State
  const [selectedTtsProvider, setSelectedTtsProvider] = useState<SttTtsProvider>('openai');
  const [selectedTtsModel, setSelectedTtsModel] = useState<string | null>(null);

  // Ollama LLM State (for local analysis)
  const [selectedOllamaModel, setSelectedOllamaModel] = useState<string>('none');

  // Prompt State
  const [promptTitle, setPromptTitle] = useState('');
  const [promptSummary, setPromptSummary] = useState('');
  const [promptTranscript, setPromptTranscript] = useState('');

  // Recording Behavior State
  const [autoTranscribeAfterRecording, setAutoTranscribeAfterRecording] = useState(true);
  
  // Streaming Transcription State
  const [enableStreamingTranscription, setEnableStreamingTranscription] = useState(false);
  const [autoGenerateSummaryAfterStreaming, setAutoGenerateSummaryAfterStreaming] = useState(false);
  
  // Language Preference State
  const [preferredLanguage, setPreferredLanguage] = useState<'fr' | 'en'>('fr');

  const [apiKeyInputs, setApiKeyInputs] = useState({ openai: '', anthropic: '', google: '', mistral: '' });

  const { license, isEnterprise, upgradeUrl } = useLicense();
  
  // Check Ollama availability and installed models
  const checkOllamaStatus = async () => {
    if (preferredTranscriptionProvider !== 'local') return;
    
    setOllamaStatus(prev => ({ ...prev, checking: true }));
    
    try {
      const OLLAMA_URL = import.meta.env.VITE_OLLAMA_URL || 'http://localhost:11434';
      const response = await fetch(`${OLLAMA_URL}/api/tags`, {
        method: 'GET',
        signal: AbortSignal.timeout(3000),
      });
      
      if (response.ok) {
        const data = await response.json();
        const installedModels = data.models?.map((m: any) => m.name.split(':')[0]) || [];
        
        setOllamaStatus({
          available: true,
          models: installedModels,
          checking: false,
        });
      } else {
        setOllamaStatus({ available: false, models: [], checking: false });
      }
    } catch (error) {
      setOllamaStatus({ available: false, models: [], checking: false });
    }
  };
  
  // Check PyTorch service availability
  const checkPyTorchStatus = async () => {
    if (preferredTranscriptionProvider !== 'local') return;
    
    setPytorchStatus(prev => ({ ...prev, checking: true }));
    
    try {
      const PYTORCH_URL = import.meta.env.VITE_PYTORCH_SERVICE_URL || 'http://localhost:8000';
      const response = await fetch(`${PYTORCH_URL}/status`, {
        method: 'GET',
        signal: AbortSignal.timeout(3000),
      });
      
      if (response.ok) {
        const data = await response.json();
        
        setPytorchStatus({
          available: true,
          diarization: data.models?.diarization === true,
          checking: false,
        });
      } else {
        setPytorchStatus({ available: false, diarization: false, checking: false });
      }
    } catch (error) {
      setPytorchStatus({ available: false, diarization: false, checking: false });
    }
  };
  
  const checkWhisperXStatus = async () => {
    if (preferredTranscriptionProvider !== 'local') return;
    
    setWhisperXStatus(prev => ({ ...prev, checking: true }));
    
    try {
      const WHISPERX_URL = import.meta.env.VITE_WHISPERX_URL || 'http://localhost:8082';
      const response = await fetch(`${WHISPERX_URL}/health`, {
        method: 'GET',
        signal: AbortSignal.timeout(3000),
      });
      
      if (response.ok) {
        const data = await response.json();
        
        setWhisperXStatus({
          available: true,
          diarization: data.diarization_available === true,
          checking: false,
          device: data.device || 'cpu',
        });
        
        // Fetch Pyannote models list if WhisperX is available
        await fetchPyannoteModels();
      } else {
        setWhisperXStatus({ available: false, diarization: false, checking: false, device: 'cpu' });
      }
    } catch (error) {
      setWhisperXStatus({ available: false, diarization: false, checking: false, device: 'cpu' });
    }
  };
  
  // Download Ollama model
  const handleDownloadModel = async () => {
    if (!selectedOllamaModel || selectedOllamaModel === 'none') return;
    
    setDownloadingModel(true);
    const toastId = toast.loading(`üì• Downloading ${selectedOllamaModel}... This may take a few minutes.`);
    
    try {
      await pullModel(selectedOllamaModel);
      toast.success(`‚úÖ ${selectedOllamaModel} downloaded successfully!`, { id: toastId });
      
      // Refresh status to show the new model
      await checkOllamaStatus();
    } catch (error) {
      console.error('Failed to download model:', error);
      toast.error(
        `‚ùå Failed to download model. Make sure Ollama is running and you have enough disk space.`,
        { id: toastId }
      );
    } finally {
      setDownloadingModel(false);
    }
  };

  // Download Pyannote models for diarization
  // Fetch Pyannote models list
  const fetchPyannoteModels = async () => {
    try {
      const response = await fetch('http://localhost:8082/pyannote-models', {
        method: 'GET',
        signal: AbortSignal.timeout(3000),
      });

      if (!response.ok) return;

      const data = await response.json();
      if (data.available && data.models) {
        setPyannoteModels(data.models);
      }
    } catch (error) {
      console.error('Failed to fetch Pyannote models:', error);
    }
  };

  // Download all Pyannote models at once
  const handleDownloadPyannote = async () => {
    setDownloadingPyannote(true);
    const toastId = toast.loading(`üì• Downloading all Pyannote models... This may take 5-10 minutes.`);
    
    try {
      const response = await fetch('http://localhost:8082/download-models', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ model: 'pyannote' })
      });
      
      if (!response.ok) {
        throw new Error(`HTTP ${response.status}`);
      }
      
      toast.success(`‚úÖ All Pyannote models downloaded successfully!`, { id: toastId });
      
      // Refresh models list and WhisperX status
      await fetchPyannoteModels();
      await checkWhisperXStatus();
    } catch (error) {
      console.error('Failed to download Pyannote:', error);
      toast.error(
        `‚ùå Failed to download Pyannote models. Make sure WhisperX is running and you've accepted HuggingFace conditions.`,
        { id: toastId, duration: 6000 }
      );
    } finally {
      setDownloadingPyannote(false);
    }
  };
  
  useEffect(() => {
    fetchProfileAndKeys();
  }, []);
  
  // Check Ollama, PyTorch, and WhisperX status when transcription provider changes to local
  useEffect(() => {
    if (preferredTranscriptionProvider === 'local') {
      checkOllamaStatus();
      checkPyTorchStatus();
      checkWhisperXStatus();
    }
  }, [preferredTranscriptionProvider]);
  
  // Re-check PyTorch and WhisperX when transcription model changes (to detect SERVER models and diarization)
  useEffect(() => {
    if (preferredTranscriptionProvider === 'local' && preferredTranscriptionModel) {
      const selectedModel = transcriptionModels.local.find(m => m.id === preferredTranscriptionModel);
      if (selectedModel && (selectedModel as any).requiresServer) {
        checkPyTorchStatus();
      }
      if (selectedModel && (selectedModel as any).supportsDiarization) {
        checkWhisperXStatus();
      }
    }
  }, [preferredTranscriptionModel]);

  useEffect(() => {
    if(!loading) setHasChanges(true);
  }, [selectedLlmProvider, selectedLlmModel, preferredTranscriptionProvider, preferredTranscriptionModel, selectedTtsProvider, selectedTtsModel, promptTitle, promptSummary, promptTranscript, autoTranscribeAfterRecording, enableStreamingTranscription, autoGenerateSummaryAfterStreaming, preferredLanguage]);
  

  async function fetchProfileAndKeys() {
    try {
      setLoading(true);
      const { data: { user } } = await supabase.auth.getUser();
      if (!user) {
        navigate('/auth/login');
        return;
      }

      const { data: profileData, error: profileError } = await supabase
        .from('profiles')
        .select('*')
        .eq('id', user.id)
        .maybeSingle();

      if (profileError) throw profileError;

      // Set initial state from profile
      const llmProvider = profileData.preferred_llm as LlmProvider || 'openai';
      setSelectedLlmProvider(llmProvider);
      setSelectedLlmModel(profileData.preferred_llm_model || llmModels[llmProvider][0].id);
      
      // Load Ollama model preference (stored in same column but used for local transcriptions)
      setSelectedOllamaModel(profileData.preferred_llm_model || 'none');

      const sttProvider = profileData.preferred_transcription_provider as SttTtsProvider || 'openai';
      setPreferredTranscriptionProvider(sttProvider);
      setPreferredTranscriptionModel(profileData.preferred_transcription_model || transcriptionModels[sttProvider][0].id);

      const ttsProvider = profileData.preferred_tts_provider as SttTtsProvider || 'openai';
      setSelectedTtsProvider(ttsProvider);
      setSelectedTtsModel(profileData.preferred_tts_model || ttsModels[ttsProvider][0].id);

      // Set prompt state from profile or defaults
      setPromptTitle(profileData.prompt_title || 'Generate a short, descriptive title for the meeting in French.');
      setPromptSummary(profileData.prompt_summary || 'Provide a concise one-paragraph summary of the key discussion points and decisions, in French.');
      setPromptTranscript(profileData.prompt_transcript || `A detailed, diarized transcript. Here's how to identify speakers:
- **Priority 1:** If a speaker introduces themselves or is named (e.g., "Hello, this is Marc," "Paul, what do you think?"), use that name as their identifier for all their speech segments.
- **Priority 2:** If names are not mentioned, use generic identifiers like "Locuteur_01", "Locuteur_02", etc.
- **Crucial Rule:** If you only detect one distinct voice throughout the recording, all text must be attributed to a single speaker (e.g., "Locuteur_01" or their identified name). Do NOT invent a second speaker.
- - Ensure each speech segment is correctly attributed to the speaker.`);

      // Set recording behavior preference
      setAutoTranscribeAfterRecording(profileData.auto_transcribe_after_recording ?? true);
      
      // Set streaming transcription preference
      setEnableStreamingTranscription(profileData.enable_streaming_transcription ?? false);
      setAutoGenerateSummaryAfterStreaming(profileData.auto_generate_summary_after_streaming ?? false);
      
      // Set language preference
      setPreferredLanguage(profileData.preferred_language || 'fr');
      
      const { data: keysData, error: keysError } = await supabase
        .from('api_keys')
        .select('provider, id')
        .eq('user_id', user.id);

      if (keysError) throw keysError;
      setApiKeys(keysData || []);

    } catch (error: any) {
      toast.error(error.message);
    } finally {
      setLoading(false);
      // Wait a tick before enabling saves to prevent instant "hasChanges" on load
      setTimeout(() => setHasChanges(false), 0);
    }
  }

  const handleApiKeySave = async (provider: string) => {
    const key = apiKeyInputs[provider as keyof typeof apiKeyInputs];
    if (!key) return toast.error('Please enter an API key.');

    const { data: { user } } = await supabase.auth.getUser();
    if (!user) return;

    const { error } = await supabase
      .from('api_keys')
      .upsert({ user_id: user.id, provider, encrypted_key: key }, { onConflict: 'user_id, provider' });

    if (error) return toast.error(error.message);
    toast.success(`${provider} API key saved!`);
    setApiKeyInputs(prev => ({ ...prev, [provider]: '' }));
    setApiKeys(prev => [...prev, { provider }]);
  };

  async function handleSaveModelSettings() {
    const { data: { user } } = await supabase.auth.getUser();
    if (!user) return;
    
    const updates = {
      id: user.id,
      email: user.email,
      updated_at: new Date().toISOString(),
      preferred_llm: selectedLlmProvider,
      // Use Ollama model for local transcriptions, cloud LLM model otherwise
      preferred_llm_model: preferredTranscriptionProvider === 'local' ? selectedOllamaModel : selectedLlmModel,
      preferred_transcription_provider: preferredTranscriptionProvider,
      preferred_transcription_model: preferredTranscriptionModel,
      preferred_tts_provider: selectedTtsProvider,
      preferred_tts_model: selectedTtsModel,
      prompt_title: promptTitle,
      prompt_summary: promptSummary,
      prompt_transcript: promptTranscript,
      auto_transcribe_after_recording: autoTranscribeAfterRecording,
      enable_streaming_transcription: enableStreamingTranscription,
      auto_generate_summary_after_streaming: autoGenerateSummaryAfterStreaming,
      preferred_language: preferredLanguage,
    };

    const { error } = await supabase.from('profiles').upsert(updates);
    if (error) return toast.error(error.message);
    
    toast.success('Settings saved!');
    setHasChanges(false);
  }

  async function handleLogout() {
    await supabase.auth.signOut();
    navigate('/auth/login');
  }

  // Run benchmark automatically when local provider is selected
  useEffect(() => {
    if (preferredTranscriptionProvider === 'local' && !benchmark && !isBenchmarking) {
      handleRunBenchmark();
    }
  }, [preferredTranscriptionProvider, benchmark, isBenchmarking]);

  const handleRunBenchmark = async () => {
    setIsBenchmarking(true);
    try {
      const result = await runBenchmark();
      console.log('Benchmark completed:', result);
    } catch (error) {
      console.error('Benchmark failed:', error);
    } finally {
      setIsBenchmarking(false);
    }
  };

  // Get ALL models with annotations based on device capabilities
  const getRecommendedModels = () => {
    if (!benchmark) return transcriptionModels.local;
    
    const allModels = transcriptionModels.local;
    
    // Annoter TOUS les mod√®les selon les capacit√©s de l'appareil
    return allModels.map(model => {
      const isRecommended = model.id === benchmark.recommendedModel;
      const isHeavy = model.id.includes('large') || model.id.includes('medium');
      const requiresServer = (model as any).requiresServer === true;
      
      let annotation = '';
      
      if (isRecommended) {
        annotation = ' üéØ RECOMMAND√â';
      } else if (requiresServer) {
        annotation = ' (Serveur PyTorch requis)';
      } else if (benchmark.deviceClass === 'low-end' && isHeavy) {
        annotation = ' ‚ö†Ô∏è PEUT √âCHOUER';
      } else if (benchmark.deviceClass === 'mid-range' && model.id.includes('large')) {
        annotation = ' ‚ö†Ô∏è TR√àS LOURD';
      }
      
      return {
        ...model,
        name: model.name + annotation
      };
    });
  };

  if (loading) return <div className="p-8 text-center">Loading settings...</div>;

  return (
    <div className="min-h-screen bg-gradient-to-br from-slate-50 via-blue-50 to-indigo-100 dark:from-gray-900 dark:via-slate-800 dark:to-gray-900">
      <div className="relative overflow-hidden pt-8 pb-16">
        <div className="absolute inset-0 bg-gradient-to-r from-blue-600/10 via-purple-600/10 to-indigo-600/10"></div>
        <div className="relative max-w-4xl mx-auto px-4 sm:px-6 lg:px-8">
          
          {/* Header */}
          <div className="text-center mb-12">
            <div className="inline-flex items-center px-4 py-2 rounded-full bg-white/80 dark:bg-gray-800/80 backdrop-blur-sm border border-gray-200/50 dark:border-gray-700/50 shadow-lg mb-6">
              <Settings className="w-5 h-5 text-blue-500 mr-2" />
              <span className="text-sm font-medium text-gray-700 dark:text-gray-300">Application Settings</span>
            </div>
            <h1 className="text-4xl md:text-5xl font-bold bg-gradient-to-r from-gray-900 via-blue-800 to-purple-800 dark:from-white dark:via-blue-200 dark:to-purple-200 bg-clip-text text-transparent mb-4">
              Settings
            </h1>
            <div className="flex items-center justify-center gap-3">
              {isEnterprise() ? (
                <span className="inline-flex items-center px-4 py-2 rounded-full bg-gradient-to-r from-blue-500 to-indigo-600 text-white text-sm font-medium shadow-lg">
                  üöÄ Enterprise Edition
                </span>
              ) : (
                <span className="inline-flex items-center px-4 py-2 rounded-full bg-gradient-to-r from-gray-100 to-gray-200 dark:from-gray-700 dark:to-gray-600 text-gray-800 dark:text-gray-200 text-sm font-medium shadow-lg">
                  üÜì Community Edition
                </span>
              )}
            </div>
          </div>

          <div className="space-y-8">

          {!isEnterprise() && (
            <div className="mb-6 p-4 bg-gradient-to-r from-blue-50 to-indigo-50 dark:from-blue-900/20 dark:to-indigo-900/20 border border-blue-200 dark:border-blue-700/50 rounded-lg">
              <div className="flex items-center justify-between">
                <div>
                  <h3 className="text-sm font-medium text-blue-800 dark:text-blue-200">
                    üöÄ Want more features?
                  </h3>
                  <p className="text-xs text-blue-700 dark:text-blue-300 mt-1">
                    Upgrade to Enterprise for cloud AI, team collaboration, and priority support
                  </p>
                </div>
                <button
                  onClick={() => window.open(upgradeUrl, '_blank')}
                  className="px-4 py-2 bg-gradient-to-r from-blue-500 to-indigo-600 hover:from-blue-600 hover:to-indigo-700 text-white text-sm font-medium rounded-lg transition-colors"
                >
                  Upgrade
                </button>
              </div>
            </div>
          )}

          {/* License Information */}
          <div className="mb-8 p-6 bg-white/80 dark:bg-gray-800/80 backdrop-blur-sm rounded-xl border border-gray-200/50 dark:border-gray-700/50 shadow-xl">
            <h2 className="text-lg font-semibold text-gray-900 dark:text-white mb-4">
              üìÑ License Information
            </h2>
            <div className="grid md:grid-cols-2 gap-4">
              <div>
                <div className="text-sm text-gray-600 dark:text-gray-400">License Type</div>
                <div className="font-medium text-gray-900 dark:text-white">
                  {license.type === 'enterprise' ? 'üíº Enterprise' : 'üÜì Community (MIT)'}
                </div>
              </div>
              <div>
                <div className="text-sm text-gray-600 dark:text-gray-400">Support Level</div>
                <div className="font-medium text-gray-900 dark:text-white">
                  {license.metadata?.supportLevel === 'premium' ? 'üöÄ Priority Support' : 'üë• Community Support'}
                </div>
              </div>
              {license.metadata?.organizationId && (
                <div>
                  <div className="text-sm text-gray-600 dark:text-gray-400">Organization</div>
                  <div className="font-medium text-gray-900 dark:text-white">{license.metadata.organizationId}</div>
                </div>
              )}
              {license.metadata?.licenseKey && (
                <div>
                  <div className="text-sm text-gray-600 dark:text-gray-400">License Key</div>
                  <div className="font-mono text-sm text-gray-700 dark:text-gray-300">
                    {license.metadata.licenseKey.slice(0, 8)}...{license.metadata.licenseKey.slice(-4)}
                  </div>
                </div>
              )}
            </div>
            {!isEnterprise() && (
              <div className="mt-4 pt-4 border-t border-gray-200/50 dark:border-gray-700/50">
                <div className="text-sm text-gray-600 dark:text-gray-400">
                  üìã Want to see what Enterprise includes? 
                  <a href={upgradeUrl} target="_blank" rel="noopener noreferrer" className="ml-1 text-blue-600 dark:text-blue-400 hover:text-blue-700 dark:hover:text-blue-300 font-medium">
                    View comparison ‚Üí
                  </a>
                </div>
              </div>
            )}
          </div>

                     {/* Existing Transcription Settings */}
           <Card>
             <div className="p-6">
               <h2 className="text-xl font-bold">üéôÔ∏è Model Settings</h2>
               <p className="mt-1 text-sm text-gray-500">Choose the AI models for different tasks.</p>
               
               {/* Show enterprise status */}
               <div className="mt-4 mb-6 p-3 bg-gray-50 dark:bg-gray-700/30 rounded-lg">
                 <div className="flex items-center justify-between">
                   <div className="text-sm">
                     <span className="font-medium text-gray-900 dark:text-white">License: </span>
                     {isEnterprise() ? (
                       <span className="text-blue-600 dark:text-blue-400 font-medium">üíº Enterprise</span>
                     ) : (
                       <span className="text-gray-600 dark:text-gray-300">üÜì Community (MIT)</span>
                     )}
                   </div>
                   {!isEnterprise() && (
                     <button
                       onClick={() => window.open(upgradeUrl, '_blank')}
                       className="px-3 py-1 bg-blue-500 hover:bg-blue-600 text-white text-xs rounded-lg transition-colors"
                     >
                       Upgrade
                     </button>
                   )}
                 </div>
               </div>
             </div>
             
             <div className="p-6 pt-0 space-y-6">
               {/* Transcription */}
               <div>
                 <SettingSelectRow
                   title="Transcription Settings"
                   selectedProvider={preferredTranscriptionProvider}
                   setSelectedProvider={(p) => setPreferredTranscriptionProvider(p as SttTtsProvider)}
                   providers={['openai', 'google', 'mistral', 'local']}
                   selectedModel={preferredTranscriptionModel}
                   setSelectedModel={setPreferredTranscriptionModel}
                   models={{
                     ...transcriptionModels,
                     local: preferredTranscriptionProvider === 'local' ? getRecommendedModels() : transcriptionModels.local
                   }}
                 />
                 
                {/* PyTorch Service Status (only for SERVER models) */}
                {preferredTranscriptionProvider === 'local' && preferredTranscriptionModel && (() => {
                  const selectedModel = transcriptionModels.local.find(m => m.id === preferredTranscriptionModel);
                  return selectedModel && (selectedModel as any).requiresServer;
                })() && (
                  <div className="mt-4 p-4 bg-orange-50/50 dark:bg-orange-900/10 rounded-xl border border-orange-200/50 dark:border-orange-700/50">
                    <div className="flex items-start gap-3 mb-3">
                      <div className="w-8 h-8 rounded-lg bg-gradient-to-r from-orange-500 to-red-600 flex items-center justify-center flex-shrink-0">
                        <span className="text-white text-lg">üñ•Ô∏è</span>
                      </div>
                      <div className="flex-1">
                        <h3 className="text-sm font-semibold text-gray-900 dark:text-white">
                          PyTorch Transcription Service
                        </h3>
                        <p className="text-xs text-gray-600 dark:text-gray-400 mt-0.5">
                          Server-side Whisper models (Medium, Large) with optional diarization
                        </p>
                      </div>
                    </div>
                    
                    {pytorchStatus.checking ? (
                      <div className="mt-3 p-3 bg-gray-50 dark:bg-gray-800/50 border border-gray-200 dark:border-gray-700/50 rounded-lg">
                        <p className="text-xs text-gray-600 dark:text-gray-400">
                          üîÑ Checking PyTorch service status...
                        </p>
                      </div>
                    ) : pytorchStatus.available ? (
                      <div className="mt-3 p-3 bg-green-50 dark:bg-green-900/20 border border-green-200 dark:border-green-700/50 rounded-lg">
                        <p className="text-xs text-green-800 dark:text-green-200">
                          ‚úÖ <strong>PyTorch service is running!</strong>
                        </p>
                        <p className="text-xs text-green-700 dark:text-green-300 mt-1">
                          {pytorchStatus.diarization ? (
                            <>üé≠ <strong>Diarization enabled</strong> - Speaker separation available</>
                          ) : (
                            <>
                              ‚ö†Ô∏è <strong>Diarization disabled</strong> - Set HUGGINGFACE_TOKEN in docker-compose.monorepo.yml
                              <button
                                onClick={async () => {
                                  try {
                                    const toastId = toast.loading('üì• Downloading Pyannote models... This may take a few minutes.');
                                    const response = await fetch('http://localhost:8000/download-pyannote', {
                                      method: 'POST'
                                    });
                                    if (response.ok) {
                                      toast.success('‚úÖ Pyannote models downloaded! Diarization enabled.', { id: toastId });
                                      await checkPyTorchStatus();
                                    } else {
                                      const error = await response.json();
                                      toast.error(`‚ùå ${error.detail}`, { id: toastId });
                                    }
                                  } catch (error) {
                                    toast.error('‚ùå Failed to download Pyannote models');
                                  }
                                }}
                                className="ml-2 text-xs px-2 py-1 bg-purple-600 text-white rounded hover:bg-purple-700"
                              >
                                üì• Download Pyannote
                              </button>
                            </>
                          )}
                        </p>
                      </div>
                    ) : (
                      <div className="mt-3 p-3 bg-blue-50 dark:bg-blue-900/20 border border-blue-200 dark:border-blue-700/50 rounded-lg">
                        <p className="text-xs text-blue-800 dark:text-blue-200 mb-2">
                          üì¶ <strong>Start PyTorch service:</strong>
                        </p>
                        <code className="text-xs bg-gray-900 text-green-400 p-2 rounded block font-mono">
                          docker-compose -f docker-compose.monorepo.yml --profile pytorch up -d
                        </code>
                        <p className="text-xs text-blue-700 dark:text-blue-300 mt-2">
                          üí° For diarization (speaker identification), set HUGGINGFACE_TOKEN in docker-compose.monorepo.yml
                        </p>
                        <button
                          onClick={checkPyTorchStatus}
                          className="mt-2 text-xs text-blue-600 dark:text-blue-400 hover:underline"
                        >
                          üîÑ Check again
                        </button>
                      </div>
                    )}
                  </div>
                )}
                
                {/* WhisperX Service Status (only for DIARIZATION models) */}
                {preferredTranscriptionProvider === 'local' && preferredTranscriptionModel && (() => {
                  const selectedModel = transcriptionModels.local.find(m => m.id === preferredTranscriptionModel);
                  return selectedModel && (selectedModel as any).supportsDiarization;
                })() && (
                  <div className="mt-4 p-4 bg-violet-50/50 dark:bg-violet-900/10 rounded-xl border border-violet-200/50 dark:border-violet-700/50">
                    <div className="flex items-start gap-3 mb-3">
                      <div className="w-8 h-8 rounded-lg bg-gradient-to-r from-violet-600 to-purple-600 flex items-center justify-center flex-shrink-0">
                        <span className="text-white text-lg">üèÜ</span>
                      </div>
                      <div className="flex-1">
                        <h3 className="text-sm font-semibold text-gray-900 dark:text-white">
                          WhisperX Ultra-Fast Diarization
                        </h3>
                        <p className="text-xs text-gray-600 dark:text-gray-400 mt-0.5">
                          6x faster than PyTorch + Pyannote (30-40s vs 4min per hour)
                        </p>
                      </div>
                    </div>
                    
                    {whisperXStatus.checking ? (
                      <div className="mt-3 p-3 bg-gray-50 dark:bg-gray-800/50 border border-gray-200 dark:border-gray-700/50 rounded-lg">
                        <p className="text-xs text-gray-600 dark:text-gray-400">
                          üîç Checking WhisperX service...
                        </p>
                      </div>
                    ) : whisperXStatus.available ? (
                      <div className="mt-3 p-3 bg-green-50 dark:bg-green-900/20 border border-green-200 dark:border-green-700/50 rounded-lg">
                        <p className="text-xs text-green-800 dark:text-green-200">
                          ‚úÖ <strong>WhisperX service is running!</strong>
                        </p>
                        <p className="text-xs text-green-700 dark:text-green-300 mt-1">
                          {whisperXStatus.diarization ? (
                            <>üé≠ <strong>Diarization enabled</strong> - Ultra-fast speaker separation on <strong>{whisperXStatus.device.toUpperCase()}</strong></>
                          ) : (
                            <>‚ö†Ô∏è <strong>Diarization disabled</strong> - Download Pyannote models below</>
                          )}
                        </p>
                        <p className="text-xs text-green-600 dark:text-green-400 mt-2">
                          ‚ö° <strong>Performance:</strong> {whisperXStatus.device === 'cuda' ? '18x faster than PyTorch (GPU)' : '6x faster than PyTorch (CPU)'}
                        </p>
                        
                        {/* Bouton pour t√©l√©charger Pyannote si diarization non disponible */}
                        {!whisperXStatus.diarization && (
                          <div className="mt-3 pt-3 border-t border-green-200 dark:border-green-700">
                            <p className="text-xs text-green-700 dark:text-green-300 mb-3">
                              üé≠ <strong>Pyannote Models for Diarization:</strong>
                            </p>
                            
                            {/* Pyannote Models List */}
                            {pyannoteModels.length > 0 ? (
                              <div className="space-y-2">
                                {pyannoteModels.map((model) => (
                                  <div 
                                    key={model.id}
                                    className={`flex items-center justify-between p-2 rounded-lg border ${
                                      model.main 
                                        ? 'bg-violet-50 dark:bg-violet-900/20 border-violet-300 dark:border-violet-700' 
                                        : 'bg-gray-50 dark:bg-gray-800/50 border-gray-200 dark:border-gray-700'
                                    }`}
                                  >
                                    <div className="flex-1">
                                      <div className="flex items-center gap-2">
                                        <span className={`text-xs font-medium ${
                                          model.main ? 'text-violet-900 dark:text-violet-100' : 'text-gray-700 dark:text-gray-300'
                                        }`}>
                                          {model.name}
                                        </span>
                                        {model.main && (
                                          <span className="text-[10px] px-1.5 py-0.5 bg-violet-500 text-white rounded font-semibold">
                                            üì¶ MAIN MODEL
                                          </span>
                                        )}
                                        {!model.main && (
                                          <span className="text-[10px] px-1.5 py-0.5 bg-gray-300 dark:bg-gray-600 text-gray-700 dark:text-gray-300 rounded">
                                            üîÑ AUTO
                                          </span>
                                        )}
                                        {model.downloaded && (
                                          <span className="text-[10px] px-1.5 py-0.5 bg-green-100 dark:bg-green-900 text-green-700 dark:text-green-300 rounded">
                                            ‚úì INSTALLED
                                          </span>
                                        )}
                                      </div>
                                      <p className="text-[10px] text-gray-600 dark:text-gray-400 mt-0.5">
                                        {model.description} ‚Ä¢ {model.size}
                                      </p>
                                    </div>
                                  </div>
                                ))}
                                
                                {/* Big Download button if main model not downloaded */}
                                {pyannoteModels.some(m => m.main && !m.downloaded) && (
                                  <button
                                    onClick={handleDownloadPyannote}
                                    disabled={downloadingPyannote}
                                    className="w-full mt-3 px-4 py-3 bg-gradient-to-r from-violet-500 to-purple-500 hover:from-violet-600 hover:to-purple-600 disabled:from-gray-400 disabled:to-gray-400 text-white text-sm font-semibold rounded-lg shadow-md hover:shadow-lg transition-all flex items-center justify-center gap-2"
                                  >
                                    <span className="text-lg">üì•</span>
                                    <span>{downloadingPyannote ? 'Downloading...' : 'Download Main Model + Dependencies (2.88 GB total)'}</span>
                                  </button>
                                )}
                                
                                {/* All installed message */}
                                {pyannoteModels.every(m => m.downloaded) && (
                                  <div className="mt-3 p-2 bg-green-50 dark:bg-green-900/20 border border-green-300 dark:border-green-700 rounded-lg">
                                    <p className="text-xs text-green-700 dark:text-green-300 text-center font-medium">
                                      ‚úÖ All models installed! Diarization ready.
                                    </p>
                                  </div>
                                )}
                              </div>
                            ) : (
                              <p className="text-xs text-gray-500 dark:text-gray-400">
                                Loading models list...
                              </p>
                            )}
                            
                            <p className="text-xs text-green-600 dark:text-green-400 mt-3">
                              üí° Requires accepting conditions on HuggingFace first
                            </p>
                            <div className="text-xs text-green-600 dark:text-green-400 mt-1 space-y-1">
                              <a 
                                href="https://huggingface.co/pyannote/speaker-diarization-3.1" 
                                target="_blank" 
                                rel="noopener noreferrer"
                                className="block hover:underline"
                              >
                                ‚Üí Accept speaker-diarization-3.1 ‚Üó
                              </a>
                              <a 
                                href="https://huggingface.co/pyannote/segmentation-3.0" 
                                target="_blank" 
                                rel="noopener noreferrer"
                                className="block hover:underline"
                              >
                                ‚Üí Accept segmentation-3.0 ‚Üó
                              </a>
                            </div>
                          </div>
                        )}
                      </div>
                    ) : (
                      <div className="mt-3 p-3 bg-blue-50 dark:bg-blue-900/20 border border-blue-200 dark:border-blue-700/50 rounded-lg">
                        <p className="text-xs text-blue-800 dark:text-blue-200 mb-2">
                          üì¶ <strong>Start WhisperX service (optional, but MUCH faster):</strong>
                        </p>
                        <code className="text-xs bg-gray-900 text-green-400 p-2 rounded block font-mono">
                          docker-compose -f docker-compose.monorepo.yml --profile whisperx up -d
                        </code>
                        <p className="text-xs text-blue-700 dark:text-blue-300 mt-2">
                          üí° Requires HUGGINGFACE_TOKEN in docker-compose.monorepo.yml for diarization
                        </p>
                        <p className="text-xs text-violet-600 dark:text-violet-400 mt-2">
                          üèÜ <strong>Why WhisperX?</strong> Uses faster-whisper (C++ optimized) + native diarization = 6x faster!
                        </p>
                        <button
                          onClick={checkWhisperXStatus}
                          className="mt-2 text-xs text-blue-600 dark:text-blue-400 hover:underline"
                        >
                          üîÑ Check again
                        </button>
                      </div>
                    )}
                  </div>
                )}
                
                {/* Feature gate for cloud providers */}
                {preferredTranscriptionProvider !== 'local' && (
                  <FeatureGate feature="cloudAIProviders">
                    <div className="mt-3 p-3 bg-green-50 dark:bg-green-900/20 border border-green-200 dark:border-green-700/50 rounded-lg">
                      <p className="text-sm text-green-800 dark:text-green-200">
                        üéâ Enterprise cloud AI features enabled!
                      </p>
                    </div>
                  </FeatureGate>
                )}
                
                {/* Ollama LLM Model Selection (only for local transcriptions) */}
                {preferredTranscriptionProvider === 'local' && (
                  <div className="mt-4 p-4 bg-purple-50/50 dark:bg-purple-900/10 rounded-xl border border-purple-200/50 dark:border-purple-700/50">
                    <div className="flex items-start gap-3 mb-3">
                      <div className="w-8 h-8 rounded-lg bg-gradient-to-r from-purple-500 to-pink-600 flex items-center justify-center flex-shrink-0">
                        <span className="text-white text-lg">ü¶ô</span>
                      </div>
                      <div className="flex-1">
                        <h3 className="text-sm font-semibold text-gray-900 dark:text-white">
                          Local LLM for Title & Summary
                        </h3>
                      <p className="text-xs text-gray-600 dark:text-gray-400 mt-0.5">
                        Ollama model for generating meeting titles and summaries (100% local, no API needed)
                      </p>
                      <div className="mt-2 p-2 bg-orange-50 dark:bg-orange-900/20 border border-orange-200 dark:border-orange-700/50 rounded-lg">
                        <p className="text-xs text-orange-800 dark:text-orange-200 mb-1">
                          ‚ö†Ô∏è <strong>RAM Required:</strong> Increase Docker memory to at least 6 GB in Docker Desktop Settings ‚Üí Resources
                        </p>
                        <p className="text-xs text-orange-800 dark:text-orange-200">
                          ‚è±Ô∏è <strong>Slow CPU?</strong> Generation can take 5-10 minutes. Use "None" for instant results or upgrade to cloud APIs.
                        </p>
                      </div>
                      </div>
                    </div>
                    
                    <select
                      value={selectedOllamaModel}
                      onChange={(e) => {
                        setSelectedOllamaModel(e.target.value);
                        setHasChanges(true);
                      }}
                      className="w-full p-3 border border-gray-300 dark:border-gray-600 rounded-lg bg-white dark:bg-gray-700 text-gray-900 dark:text-white focus:ring-2 focus:ring-purple-500 focus:border-purple-500 transition-all"
                    >
                      {ollamaModels.map((model) => (
                        <option key={model.id} value={model.id}>
                          {model.name} - {model.description}
                        </option>
                      ))}
                    </select>
                    
                    {selectedOllamaModel !== 'none' && (
                      <>
                        {ollamaStatus.checking ? (
                          <div className="mt-3 p-3 bg-gray-50 dark:bg-gray-800/50 border border-gray-200 dark:border-gray-700/50 rounded-lg">
                            <p className="text-xs text-gray-600 dark:text-gray-400">
                              üîÑ Checking Ollama status...
                            </p>
                          </div>
                        ) : ollamaStatus.available && ollamaStatus.models.includes(selectedOllamaModel.split(':')[0]) ? (
                          <div className="mt-3 p-3 bg-green-50 dark:bg-green-900/20 border border-green-200 dark:border-green-700/50 rounded-lg">
                            <p className="text-xs text-green-800 dark:text-green-200">
                              ‚úÖ <strong>{ollamaModels.find(m => m.id === selectedOllamaModel)?.name}</strong> is ready!
                            </p>
                            <p className="text-xs text-green-700 dark:text-green-300 mt-1">
                              üí° Model size: {ollamaModels.find(m => m.id === selectedOllamaModel)?.size}
                            </p>
                          </div>
                        ) : !ollamaStatus.available ? (
                          <div className="mt-3 p-3 bg-blue-50 dark:bg-blue-900/20 border border-blue-200 dark:border-blue-700/50 rounded-lg">
                            <p className="text-xs text-blue-800 dark:text-blue-200 mb-2">
                              üì¶ <strong>Start Ollama service:</strong>
                            </p>
                            <code className="text-xs bg-gray-900 text-green-400 p-2 rounded block font-mono">
                              docker-compose -f docker-compose.monorepo.yml --profile ollama up -d
                            </code>
                            <button
                              onClick={checkOllamaStatus}
                              className="mt-2 text-xs text-blue-600 dark:text-blue-400 hover:underline"
                            >
                              üîÑ Check again
                            </button>
                          </div>
                        ) : (
                          <div className="mt-3 p-3 bg-yellow-50 dark:bg-yellow-900/20 border border-yellow-200 dark:border-yellow-700/50 rounded-lg">
                            <div className="flex items-start justify-between mb-2">
                              <div>
                                <p className="text-xs text-yellow-800 dark:text-yellow-200 font-semibold">
                                  üì• Model not installed
                                </p>
                                <p className="text-xs text-yellow-700 dark:text-yellow-300 mt-1">
                                  üíæ Size: {ollamaModels.find(m => m.id === selectedOllamaModel)?.size}
                                </p>
                              </div>
                              <button
                                onClick={handleDownloadModel}
                                disabled={downloadingModel}
                                className="px-4 py-2 bg-gradient-to-r from-yellow-500 to-orange-600 hover:from-yellow-600 hover:to-orange-700 disabled:from-gray-400 disabled:to-gray-500 text-white text-xs font-medium rounded-lg shadow-md hover:shadow-lg transition-all disabled:cursor-not-allowed flex items-center gap-2"
                              >
                                {downloadingModel ? (
                                  <>
                                    <span className="animate-spin">‚è≥</span>
                                    Downloading...
                                  </>
                                ) : (
                                  <>
                                    <span>üì•</span>
                                    Download Model
                                  </>
                                )}
                              </button>
                            </div>
                            {downloadingModel && (
                              <p className="text-xs text-yellow-700 dark:text-yellow-300 mt-2">
                                ‚è±Ô∏è This may take several minutes depending on your internet speed...
                              </p>
                            )}
                            {!downloadingModel && (
                              <button
                                onClick={checkOllamaStatus}
                                className="mt-2 text-xs text-yellow-600 dark:text-yellow-400 hover:underline"
                              >
                                üîÑ Refresh status
                              </button>
                            )}
                          </div>
                        )}
                      </>
                    )}
                    
                    {selectedOllamaModel === 'none' && (
                      <div className="mt-3 p-3 bg-gray-50 dark:bg-gray-800/50 border border-gray-200 dark:border-gray-700/50 rounded-lg">
                        <p className="text-xs text-gray-600 dark:text-gray-400">
                          ‚ö° Rule-based generation active. Fast but less intelligent. Install Ollama for better results.
                        </p>
                      </div>
                    )}
                  </div>
                )}
              </div>

              {/* LLM with enterprise gating */}
               <FeatureGate feature="cloudAIProviders" showUpgradePrompt={false}>
                 <SettingSelectRow
                   title="Primary LLM"
                   selectedProvider={selectedLlmProvider}
                   setSelectedProvider={(p) => setSelectedLlmProvider(p as LlmProvider)}
                   providers={Object.keys(llmModels)}
                   selectedModel={selectedLlmModel}
                   setSelectedModel={setSelectedLlmModel}
                   models={llmModels}
                 />
               </FeatureGate>

               {/* TTS with enterprise gating */}
               <FeatureGate feature="cloudAIProviders" showUpgradePrompt={false}>
                 <SettingSelectRow
                   title="Text-to-Speech"
                   selectedProvider={selectedTtsProvider}
                   setSelectedProvider={(p) => setSelectedTtsProvider(p as SttTtsProvider)}
                   providers={Object.keys(ttsModels)}
                   selectedModel={selectedTtsModel}
                   setSelectedModel={setSelectedTtsModel}
                   models={ttsModels}
                 />
               </FeatureGate>
             </div>
           </Card>

           {/* Recording Behavior Settings */}
           <Card>
             <div className="p-6">
               <h2 className="text-xl font-bold">üé¨ Recording Behavior</h2>
               <p className="mt-1 text-sm text-gray-500">Control how the app behaves after recording audio.</p>
             </div>
             <div className="p-6 pt-0">
               <div className="flex items-center justify-between p-4 bg-gray-50/50 dark:bg-gray-700/30 rounded-xl border border-gray-200/30 dark:border-gray-600/30">
                 <div className="flex-1">
                   <h3 className="text-sm font-medium text-gray-900 dark:text-white">
                     Auto-transcribe after recording
                   </h3>
                   <p className="text-xs text-gray-500 dark:text-gray-400 mt-1">
                     {autoTranscribeAfterRecording 
                       ? "Automatically start transcription when recording stops" 
                       : "Ask for confirmation before starting transcription"
                     }
                   </p>
                 </div>
                 <label className="relative inline-flex items-center cursor-pointer">
                   <input
                     type="checkbox"
                     checked={autoTranscribeAfterRecording}
                     onChange={(e) => setAutoTranscribeAfterRecording(e.target.checked)}
                     className="sr-only peer"
                   />
                   <div className="w-11 h-6 bg-gray-200 peer-focus:outline-none peer-focus:ring-4 peer-focus:ring-blue-300 dark:peer-focus:ring-blue-800 rounded-full peer dark:bg-gray-700 peer-checked:after:translate-x-full peer-checked:after:border-white after:content-[''] after:absolute after:top-[2px] after:left-[2px] after:bg-white after:border-gray-300 after:border after:rounded-full after:h-5 after:w-5 after:transition-all dark:border-gray-600 peer-checked:bg-blue-600"></div>
                 </label>
              </div>
              
              {/* Streaming Transcription Toggle */}
              <div className="mt-4 flex items-center justify-between p-4 bg-gradient-to-r from-violet-50 to-purple-50 dark:from-violet-900/20 dark:to-purple-900/20 rounded-xl border border-violet-200/50 dark:border-violet-700/50">
                <div className="flex-1">
                  <div className="flex items-center gap-2">
                    <h3 className="text-sm font-medium text-gray-900 dark:text-white">
                      üöÄ Live Streaming Transcription
                    </h3>
                    <span className="px-2 py-0.5 text-xs font-semibold bg-gradient-to-r from-violet-600 to-purple-600 text-white rounded-full">
                      NEW
                    </span>
                  </div>
                  <p className="text-xs text-gray-600 dark:text-gray-300 mt-1">
                    {enableStreamingTranscription 
                      ? "‚ö° Real-time transcription with live text appearing as you speak (requires WhisperX or whisper.cpp)" 
                      : "üì¶ Batch transcription after recording ends (standard mode)"
                    }
                  </p>
                  <p className="text-xs text-violet-600 dark:text-violet-400 mt-1">
                    üí° Streaming gives instant feedback - see text appear live!
                  </p>
                </div>
                <label className="relative inline-flex items-center cursor-pointer ml-4">
                  <input
                    type="checkbox"
                    checked={enableStreamingTranscription}
                    onChange={(e) => setEnableStreamingTranscription(e.target.checked)}
                    className="sr-only peer"
                  />
                  <div className="w-11 h-6 bg-gray-200 peer-focus:outline-none peer-focus:ring-4 peer-focus:ring-violet-300 dark:peer-focus:ring-violet-800 rounded-full peer dark:bg-gray-700 peer-checked:after:translate-x-full peer-checked:after:border-white after:content-[''] after:absolute after:top-[2px] after:left-[2px] after:bg-white after:border-gray-300 after:border after:rounded-full after:h-5 after:w-5 after:transition-all dark:border-gray-600 peer-checked:bg-gradient-to-r peer-checked:from-violet-600 peer-checked:to-purple-600"></div>
                </label>
              </div>
              
              {/* Auto-Generate AI Summary Toggle */}
              <div className="mt-4 flex items-center justify-between p-4 bg-gradient-to-r from-blue-50 to-indigo-50 dark:from-blue-900/20 dark:to-indigo-900/20 rounded-xl border border-blue-200/50 dark:border-blue-700/50">
                <div className="flex-1">
                  <div className="flex items-center gap-2">
                    <h3 className="text-sm font-medium text-gray-900 dark:text-white">
                      ü§ñ Auto-Generate AI Summary (Ollama)
                    </h3>
                    <span className="px-2 py-0.5 text-xs font-semibold bg-blue-600 text-white rounded-full">
                      NEW
                    </span>
                  </div>
                  <p className="text-xs text-gray-600 dark:text-gray-300 mt-1">
                    {autoGenerateSummaryAfterStreaming 
                      ? "‚ú® Automatically generate title and summary using Ollama after streaming transcription completes." 
                      : "üìù Generate title and summary manually from the meeting detail page."
                    }
                  </p>
                  <p className="text-xs text-blue-600 dark:text-blue-400 mt-1">
                    üí° Requires Ollama service to be running.
                  </p>
                </div>
                <label className="relative inline-flex items-center cursor-pointer ml-4">
                  <input
                    type="checkbox"
                    checked={autoGenerateSummaryAfterStreaming}
                    onChange={(e) => setAutoGenerateSummaryAfterStreaming(e.target.checked)}
                    className="sr-only peer"
                  />
                  <div className="w-11 h-6 bg-gray-200 peer-focus:outline-none peer-focus:ring-4 peer-focus:ring-blue-300 dark:peer-focus:ring-blue-800 rounded-full peer dark:bg-gray-700 peer-checked:after:translate-x-full peer-checked:after:border-white after:content-[''] after:absolute after:top-[2px] after:left-[2px] after:bg-white after:border-gray-300 after:border after:rounded-full after:h-5 after:w-5 after:transition-all dark:border-gray-600 peer-checked:bg-blue-600"></div>
                </label>
              </div>
              
              <div className="mt-4 p-4 bg-gray-50/50 dark:bg-gray-700/30 rounded-xl border border-gray-200/30 dark:border-gray-600/30">
                 <div>
                   <h3 className="text-sm font-medium text-gray-900 dark:text-white mb-2">
                     üåç Preferred Language / Langue pr√©f√©r√©e
                   </h3>
                   <p className="text-xs text-gray-500 dark:text-gray-400 mb-3">
                     Language for titles, summaries, and default prompts ‚Ä¢ Langue pour les titres, r√©sum√©s et prompts par d√©faut
                   </p>
                   <select
                     value={preferredLanguage}
                     onChange={(e) => setPreferredLanguage(e.target.value as 'fr' | 'en')}
                     className="w-full p-2.5 border border-gray-300 dark:border-gray-600 rounded-lg bg-white dark:bg-gray-700 text-gray-900 dark:text-white focus:ring-2 focus:ring-blue-500 focus:border-blue-500"
                   >
                     <option value="fr">üá´üá∑ Fran√ßais</option>
                     <option value="en">üá¨üáß English</option>
                   </select>
                   <p className="text-xs text-gray-500 dark:text-gray-400 mt-2">
                     {preferredLanguage === 'fr' 
                       ? "Les prompts seront optimis√©s pour chaque LLM en fran√ßais" 
                       : "Prompts will be optimized for each LLM in English"
                     }
                   </p>
                 </div>
               </div>
             </div>
           </Card>

           {/* Enterprise Features */}
           <FeatureGate feature="advancedAnalytics">
             <Card>
               <div className="p-6">
                 <h3 className="text-lg font-semibold text-gray-900">üìä Advanced Analytics</h3>
                 <p className="text-sm text-gray-500 mt-1">Enterprise analytics and monitoring</p>
                 <div className="mt-4 grid md:grid-cols-2 gap-4">
                   <label className="flex items-center space-x-2">
                     <input type="checkbox" className="rounded border-gray-300" />
                     <span className="text-sm text-gray-700">Enable usage analytics</span>
                   </label>
                   <label className="flex items-center space-x-2">
                     <input type="checkbox" className="rounded border-gray-300" />
                     <span className="text-sm text-gray-700">Performance monitoring</span>
                   </label>
                 </div>
               </div>
             </Card>
           </FeatureGate>

           <FeatureGate feature="teamCollaboration">
             <Card>
               <div className="p-6">
                 <h3 className="text-lg font-semibold text-gray-900">üë• Team Collaboration</h3>
                 <p className="text-sm text-gray-500 mt-1">Enterprise team features</p>
                 <div className="mt-4 space-y-3">
                   <div>
                     <label className="block text-sm font-medium text-gray-700 mb-2">
                       Default Sharing
                     </label>
                     <select className="w-full p-2 border border-gray-300 rounded-lg">
                       <option value="private">üîí Private</option>
                       <option value="team">üë• Team Only</option>
                       <option value="organization">üè¢ Organization</option>
                     </select>
                   </div>
                 </div>
               </div>
             </Card>
           </FeatureGate>

          {/* Feature Comparison Table */}
          <div className="mt-8">
            <FeatureComparison />
          </div>

          {/* Prompt Settings */}
          <Card>
            <div className="p-6">
                <h2 className="text-xl font-bold">Prompt Settings</h2>
                <p className="mt-1 text-sm text-gray-500">Customize the prompts used for AI analysis. These will be used by the transcription function.</p>
            </div>
            <div className="p-6 pt-0 space-y-4">
                <PromptTextarea label="Title Prompt" value={promptTitle} onChange={setPromptTitle} />
                <PromptTextarea label="Summary Prompt" value={promptSummary} onChange={setPromptSummary} />
                <PromptTextarea label="Transcript & Diarization Prompt" value={promptTranscript} onChange={setPromptTranscript} />
            </div>
          </Card>
          
          {/* API Keys */}
          <Card>
            <div className="p-6">
                <h2 className="text-xl font-bold">API Keys</h2>
                <p className="mt-1 text-sm text-gray-500">Keys are stored securely and never exposed on the client-side.</p>
            </div>
            <div className="p-6 pt-0 space-y-4">
              {Object.keys(apiKeyInputs).map(p => 
                <ApiKeyInputRow 
                  key={p}
                  provider={p}
                  hasKey={apiKeys.some(k => k.provider === p)}
                  value={apiKeyInputs[p as keyof typeof apiKeyInputs]}
                  onChange={v => setApiKeyInputs(prev => ({...prev, [p]: v}))}
                  onSave={() => handleApiKeySave(p)}
                />
              )}
            </div>
          </Card>
          
          {/* Device Performance Section */}
          {preferredTranscriptionProvider === 'local' && (
            <div className="bg-white/80 dark:bg-gray-800/80 backdrop-blur-sm p-6 rounded-xl border border-gray-200/50 dark:border-gray-700/50 shadow-xl">
              <div className="flex items-center justify-between mb-4">
                <h2 className="text-xl font-semibold text-gray-900 dark:text-white">üî¨ Device Performance</h2>
                <button
                  onClick={handleRunBenchmark}
                  disabled={isBenchmarking}
                  className="px-4 py-2 bg-blue-600 text-white rounded-lg hover:bg-blue-700 disabled:opacity-50"
                >
                  {isBenchmarking ? 'üîÑ Testing...' : 'üî¨ Run Test'}
                </button>
              </div>
              
              {benchmark && (
                <div className="space-y-3">
                  <div className="grid grid-cols-2 gap-4">
                    <div className="bg-white dark:bg-gray-700 p-3 rounded-lg">
                      <div className="text-sm text-gray-600 dark:text-gray-400">Device Class</div>
                      <div className="font-semibold capitalize text-lg text-gray-900 dark:text-white">
                        {benchmark.deviceClass === 'high-end' && 'üöÄ High-End'}
                        {benchmark.deviceClass === 'mid-range' && '‚ö° Mid-Range'}
                        {benchmark.deviceClass === 'low-end' && 'üíª Low-End'}
                      </div>
                    </div>
                    <div className="bg-white dark:bg-gray-700 p-3 rounded-lg">
                      <div className="text-sm text-gray-600 dark:text-gray-400">WebGPU Support</div>
                      <div className="font-semibold text-lg text-gray-900 dark:text-white">
                        {benchmark.webGPUSupported ? '‚úÖ Supported' : '‚ùå Not Available'}
                      </div>
                    </div>
                    <div className="bg-white dark:bg-gray-700 p-3 rounded-lg">
                      <div className="text-sm text-gray-600 dark:text-gray-400">Estimated Memory</div>
                      <div className="font-semibold text-lg text-gray-900 dark:text-white">{benchmark.estimatedMemoryGB}GB</div>
                    </div>
                    <div className="bg-white dark:bg-gray-700 p-3 rounded-lg">
                      <div className="text-sm text-gray-600 dark:text-gray-400">CPU Cores</div>
                      <div className="font-semibold text-lg text-gray-900 dark:text-white">{benchmark.cpuCores}</div>
                    </div>
                  </div>
                  
                  <div className="bg-green-50 dark:bg-green-900/20 p-4 rounded-lg border border-green-200 dark:border-green-700/50">
                    <div className="flex items-start space-x-2">
                      <span className="text-green-600 dark:text-green-400">üéØ</span>
                      <div>
                        <div className="font-semibold text-green-800 dark:text-green-200">Recommended Model</div>
                        <div className="text-green-700 dark:text-green-300">
                          {transcriptionModels.local.find(m => m.id === benchmark.recommendedModel)?.name || benchmark.recommendedModel}
                        </div>
                        <div className="text-sm text-green-600 dark:text-green-400 mt-1">
                          Optimized for your {benchmark.deviceClass} device
                          {benchmark.webGPUSupported && ' with Apple Silicon GPU acceleration'}
                        </div>
                      </div>
                    </div>
                  </div>
                  
                  {/* Local Processing Info */}
                  <div className="bg-gradient-to-r from-blue-50 to-indigo-50 dark:from-blue-900/20 dark:to-indigo-900/20 p-4 rounded-lg border border-blue-200 dark:border-blue-700/50">
                    <div className="flex items-center space-x-2 mb-2">
                      <span className="text-lg">üîí</span>
                      <h3 className="font-semibold text-blue-900 dark:text-blue-200">100% Local Processing</h3>
                    </div>
                    <p className="text-sm text-blue-800 dark:text-blue-200 mb-2">
                      Your recommended model runs completely locally for maximum privacy:
                    </p>
                    <ul className="text-xs text-blue-700 dark:text-blue-300 space-y-1 ml-4">
                      <li>‚Ä¢ üîí Zero data sent to external servers</li>
                      <li>‚Ä¢ ‚ö° No internet required after model download</li>
                      <li>‚Ä¢ üÜì No API costs or usage limits</li>
                      <li>‚Ä¢ üõ°Ô∏è Complete privacy and security</li>
                      <li>‚Ä¢ üì± Optimized for your device capabilities</li>
                    </ul>
                    <div className="mt-3 text-xs text-blue-600 dark:text-blue-400">
                      üí° Want advanced features? Voxtral is available as a cloud option with API key!
                    </div>
                  </div>
                </div>
              )}
              
              {!benchmark && !isBenchmarking && (
                <div className="text-gray-600 dark:text-gray-400">
                  Run a performance test to get personalized model recommendations for your device.
                </div>
              )}
            </div>
          )}

          <div className="flex justify-between items-center">
              <Button onClick={handleSaveModelSettings} disabled={!hasChanges || loading}>
                  {hasChanges ? 'Save Changes' : 'Saved'}
              </Button>
              <Button onClick={handleLogout} variant="danger">Logout</Button>
          </div>
          </div>
        </div>
      </div>
    </div>
  );
}

function PromptTextarea({ label, value, onChange }: { label: string; value: string; onChange: (value: string) => void; }) {
    return (
        <div>
            <label className="block text-sm font-medium text-gray-900 dark:text-white mb-1">{label}</label>
            <textarea
                value={value}
                onChange={(e) => onChange(e.target.value)}
                className="w-full p-2 border border-gray-300 dark:border-gray-600 rounded bg-white dark:bg-gray-700 text-gray-900 dark:text-white focus:ring-2 focus:ring-blue-500 focus:border-blue-500"
                rows={4}
            />
        </div>
    );
}

// Backend Badge Component - Affiche plusieurs badges
function BackendBadges({ supportsDiarization, requiresServer }: { supportsDiarization?: boolean; requiresServer?: boolean }) {
  const [whisperXAvailable, setWhisperXAvailable] = useState<boolean | null>(null);
  
  useEffect(() => {
    // Check backend availability
    checkWhisperXAvailability().then(setWhisperXAvailable).catch(() => setWhisperXAvailable(false));
  }, []);
  
  const badges = [];
  
  // Badge Backend - Priorit√© intelligente
  // üèÜ PRIORIT√â 1: WhisperX (si diarization + disponible)
  if (supportsDiarization && whisperXAvailable) {
    badges.push(
      <span key="backend" className="inline-flex items-center px-2 py-0.5 rounded text-xs font-medium bg-gradient-to-r from-violet-600 to-purple-600 text-white shadow-sm">
        üèÜ WhisperX
      </span>
    );
  }
  // üñ•Ô∏è PRIORIT√â 2: PyTorch Server (fallback pour mod√®les lourds)
  else if (requiresServer) {
    badges.push(
      <span key="backend" className="inline-flex items-center px-2 py-0.5 rounded text-xs font-medium bg-blue-100 text-blue-800 dark:bg-blue-900 dark:text-blue-200">
        <ServerIcon className="w-3 h-3 mr-1" /> PyTorch Server
      </span>
    );
  }
  // üåê PRIORIT√â 3: Browser (fallback ultime)
  else {
    badges.push(
      <span key="backend" className="inline-flex items-center px-2 py-0.5 rounded text-xs font-medium bg-green-100 text-green-800 dark:bg-green-900 dark:text-green-200">
        <GlobeIcon className="w-3 h-3 mr-1" /> Browser
      </span>
    );
  }
  
  // Badge Diarization (si support√©)
  if (supportsDiarization) {
    badges.push(
      <span key="diarization" className="inline-flex items-center px-2 py-0.5 rounded text-xs font-medium bg-purple-100 text-purple-800 dark:bg-purple-900 dark:text-purple-200">
        üé≠ Diarization
      </span>
    );
  }
  
  return <div className="flex gap-2 flex-wrap">{badges}</div>;
}

function SettingSelectRow({ title, selectedProvider, setSelectedProvider, providers, selectedModel, setSelectedModel, models }: {
  title: string;
  selectedProvider: string;
  setSelectedProvider: (provider: string) => void;
  providers: string[];
  selectedModel: string | null;
  setSelectedModel: (model: string) => void;
  models: Record<string, Model[]>;
}) {
  const selectedModelData = models[selectedProvider]?.find((m: Model) => m.id === selectedModel);
  const selectedModelDesc = selectedModelData?.description || '';
  const isLocal = selectedProvider === 'local';

  return (
    <div>
      <h3 className="text-lg font-medium text-gray-900 dark:text-white">{title}</h3>
      <div className="grid grid-cols-1 md:grid-cols-2 gap-4 mt-2">
        <div>
          <label className="block text-sm font-medium text-gray-900 dark:text-white mb-1">Provider</label>
          <select
            value={selectedProvider}
            onChange={(e) => {
              const newProvider = e.target.value;
              setSelectedProvider(newProvider);
              setSelectedModel(models[newProvider][0].id);
            }}
            className="w-full p-2 border border-gray-300 dark:border-gray-600 rounded bg-white dark:bg-gray-700 text-gray-900 dark:text-white focus:ring-2 focus:ring-blue-500 focus:border-blue-500"
          >
            {providers.map((p: string) => (
              <option key={p} value={p} className="capitalize">
                {p === 'local' ? 'Local (Browser)' : p}
              </option>
            ))}
          </select>
        </div>
        <div>
          <label className="block text-sm font-medium text-gray-900 dark:text-white mb-1">Model</label>
          <select
            value={selectedModel || ''}
            onChange={(e) => setSelectedModel(e.target.value)}
            className="w-full p-2 border border-gray-300 dark:border-gray-600 rounded bg-white dark:bg-gray-700 text-gray-900 dark:text-white focus:ring-2 focus:ring-blue-500 focus:border-blue-500 disabled:opacity-50"
            disabled={!selectedProvider}
          >
            {selectedProvider && models[selectedProvider].map((m: Model) => (
              <option key={m.id} value={m.id}>
                {m.name} {m.size && `(${m.size})`}
              </option>
            ))}
          </select>
        </div>
      </div>
      <div className="mt-2 space-y-1">
        <p className="text-sm text-gray-600 dark:text-gray-400">{selectedModelDesc}</p>
        {isLocal && selectedModel && (
          <BackendBadges 
            supportsDiarization={selectedModelData?.supportsDiarization}
            requiresServer={selectedModelData?.requiresServer}
          />
        )}
        {isLocal && selectedModelData && (
          <div className="text-xs text-gray-500 dark:text-gray-400 space-y-1">
            {selectedModelData.size && (
              <div>üì¶ <strong>Size:</strong> {selectedModelData.size}</div>
            )}
            {selectedModelData.languages && (
              <div>üåç <strong>Languages:</strong> {selectedModelData.languages}</div>
            )}
            {selectedProvider === 'local' && (
              <div className="text-blue-800 dark:text-blue-200 bg-blue-50 dark:bg-blue-900/20 border border-blue-200 dark:border-blue-700/50 p-2 rounded">
                ‚ÑπÔ∏è <strong>Privacy:</strong> Runs entirely in your browser. No data sent to external servers.
              </div>
            )}
            {selectedProvider === 'local' && (
              <div className="space-y-2">
                <div className="text-amber-800 dark:text-amber-200 bg-amber-50 dark:bg-amber-900/20 border border-amber-200 dark:border-amber-700/50 p-2 rounded">
                  üí° <strong>Tip:</strong> Start with "Moonshine Tiny" (50MB, English) or "Whisper Tiny" (39MB, multilingual). 
                  For French meetings with multiple speakers, use "Distil-Whisper Large v3" (756MB, French PRO) for best diarization. 
                  If AI fails, use cloud transcription (OpenAI/Google).
                </div>
                <div className="text-green-800 dark:text-green-200 bg-green-50 dark:bg-green-900/20 border border-green-200 dark:border-green-700/50 p-2 rounded">
                  üá´üá∑ <strong>Fran√ßais:</strong> Nouveaux mod√®les sp√©cialis√©s pour le fran√ßais ! "Whisper Small FR" (244MB) et "Distil-Whisper Large v3" (756MB) offrent une meilleure pr√©cision pour la transcription en fran√ßais et la s√©paration des locuteurs.
                </div>
                <div className="text-purple-800 dark:text-purple-200 bg-purple-50 dark:bg-purple-900/20 border border-purple-200 dark:border-purple-700/50 p-2 rounded">
                  üöÄ <strong>whisper.cpp Ultra-Rapide:</strong> Si le service whisper.cpp est actif (badge violet üöÄ), votre transcription sera 3-9x plus rapide ! Sinon, l'app utilise automatiquement WebGPU (Apple Silicon) ou le navigateur.
                </div>
              </div>
            )}
          </div>
        )}
      </div>
    </div>
  );
}

function ApiKeyInputRow({ provider, hasKey, value, onChange, onSave }: {
  provider: string;
  hasKey: boolean;
  value: string;
  onChange: (value: string) => void;
  onSave: () => void;
}) {
  const getProviderInfo = (provider: string) => {
    switch (provider) {
      case 'mistral':
        return {
          name: 'üéØ Mistral (Voxtral)',
          description: 'For revolutionary Voxtral audio models with semantic understanding',
          placeholder: hasKey ? '‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ Saved (Voxtral Ready)' : 'Enter Mistral API key for Voxtral models'
        };
      case 'openai':
        return {
          name: 'ü§ñ OpenAI',
          description: 'For GPT models and Whisper transcription',
          placeholder: hasKey ? '‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ Saved' : 'Enter OpenAI API key'
        };
      case 'anthropic':
        return {
          name: 'üß† Anthropic (Claude)',
          description: 'For advanced reasoning and analysis tasks',
          placeholder: hasKey ? '‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ Saved' : 'Enter Anthropic API key'
        };
      case 'google':
        return {
          name: 'üåü Google AI',
          description: 'For Gemini models and multimodal capabilities',
          placeholder: hasKey ? '‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ Saved' : 'Enter Google AI API key'
        };
      default:
        return {
          name: provider.charAt(0).toUpperCase() + provider.slice(1),
          description: '',
          placeholder: hasKey ? '‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢ Saved' : 'Enter your API key'
        };
    }
  };

  const providerInfo = getProviderInfo(provider);

  return (
    <div>
      <label className="block text-sm font-medium text-gray-900 dark:text-white">{providerInfo.name}</label>
      {providerInfo.description && (
        <p className="text-xs text-gray-500 dark:text-gray-400 mt-1">{providerInfo.description}</p>
      )}
      <div className="flex items-center space-x-2 mt-2">
        <input
          type="password"
          placeholder={providerInfo.placeholder}
          value={value}
          onChange={(e) => onChange(e.target.value)}
          className="w-full p-2 border border-gray-300 dark:border-gray-600 rounded bg-white dark:bg-gray-700 text-gray-900 dark:text-white placeholder-gray-500 dark:placeholder-gray-400 focus:ring-2 focus:ring-blue-500 focus:border-blue-500"
        />
        <Button onClick={onSave} disabled={!value}>Save</Button>
      </div>
    </div>
  );
}