#!/bin/bash
# Script de dÃ©ploiement VPS COMPLET - Compatible multi-OS
set -e

# Couleurs pour l'affichage
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
PURPLE='\033[0;35m'
CYAN='\033[0;36m'
NC='\033[0m'

# DÃ©tection de l'OS
OS_TYPE=""
PACKAGE_MANAGER=""
PACKAGE_UPDATE_CMD=""
PACKAGE_INSTALL_CMD=""

detect_os() {
    if [ -f /etc/os-release ]; then
        . /etc/os-release
        OS_TYPE=$ID
        case $OS_TYPE in
            ubuntu|debian)
                PACKAGE_MANAGER="apt"
                PACKAGE_UPDATE_CMD="sudo apt-get update"
                PACKAGE_INSTALL_CMD="sudo apt-get install -y"
                ;;
            fedora|centos|rhel|rocky|almalinux)
                PACKAGE_MANAGER="yum"
                if command -v dnf &> /dev/null; then
                    PACKAGE_MANAGER="dnf"
                fi
                PACKAGE_UPDATE_CMD="sudo $PACKAGE_MANAGER update -y"
                PACKAGE_INSTALL_CMD="sudo $PACKAGE_MANAGER install -y"
                ;;
            arch|manjaro)
                PACKAGE_MANAGER="pacman"
                PACKAGE_UPDATE_CMD="sudo pacman -Syu --noconfirm"
                PACKAGE_INSTALL_CMD="sudo pacman -S --noconfirm"
                ;;
            alpine)
                PACKAGE_MANAGER="apk"
                PACKAGE_UPDATE_CMD="sudo apk update"
                PACKAGE_INSTALL_CMD="sudo apk add --no-cache"
                ;;
            *)
                echo "OS non supportÃ©: $OS_TYPE"
                echo "OS supportÃ©s: Ubuntu, Debian, Fedora, CentOS, RHEL, Rocky Linux, AlmaLinux, Arch, Manjaro, Alpine"
                exit 1
                ;;
        esac
    else
        echo "Impossible de dÃ©tecter l'OS"
        exit 1
    fi
}

# Configuration - sera dÃ©finie par l'utilisateur
PROJECT_DIR=""
REQUIRED_TOOLS=("docker" "git" "openssl" "curl" "jq" "envsubst")

print_header() {
    echo -e "\n${BLUE}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
    echo -e "${BLUE}    $1${NC}"
    echo -e "${BLUE}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
}

print_success() {
    echo -e "${GREEN}âœ… $1${NC}"
}

print_error() {
    echo -e "${RED}âŒ $1${NC}"
}

print_warning() {
    echo -e "${YELLOW}âš ï¸  $1${NC}"
}

print_info() {
    echo -e "${BLUE}â„¹ï¸  $1${NC}"
}

# Fonction pour gÃ©nÃ©rer des mots de passe sÃ©curisÃ©s
generate_password() {
    openssl rand -base64 32 | tr -d "=+/" | cut -c1-25
}

# DÃ©tection de l'OS
detect_os
print_success "OS dÃ©tectÃ© : $OS_TYPE (Package Manager: $PACKAGE_MANAGER)"

# Demander le rÃ©pertoire d'installation
print_header "Configuration du rÃ©pertoire d'installation"

# Proposer le rÃ©pertoire par dÃ©faut selon l'utilisateur
DEFAULT_DIR="$HOME/antislash-talk"
print_info "RÃ©pertoire par dÃ©faut suggÃ©rÃ© : $DEFAULT_DIR"

read -p "RÃ©pertoire d'installation [$DEFAULT_DIR] : " USER_DIR
PROJECT_DIR=${USER_DIR:-$DEFAULT_DIR}

# CrÃ©er le rÃ©pertoire s'il n'existe pas
if [ ! -d "$PROJECT_DIR" ]; then
    print_info "CrÃ©ation du rÃ©pertoire $PROJECT_DIR..."
    mkdir -p "$PROJECT_DIR"
    
    # Cloner le repository si nÃ©cessaire
    if [ ! -f "$PROJECT_DIR/docker-compose.monorepo.yml" ]; then
        print_info "Clonage du repository..."
        git clone https://github.com/Lamouller/Antislash-Talk.git "$PROJECT_DIR"
    fi
fi

# VÃ©rifier qu'on a bien le projet
if [ ! -f "$PROJECT_DIR/docker-compose.monorepo.yml" ]; then
    print_error "Impossible de trouver docker-compose.monorepo.yml dans $PROJECT_DIR"
    exit 1
fi

cd "$PROJECT_DIR"
print_success "RÃ©pertoire de travail : $PROJECT_DIR"

# ASCII Art
echo -e "${CYAN}"
cat << "EOF"
    _          _   _     _           _       _____     _ _   
   / \   _ __ | |_(_)___| | __ _ ___| |__   |_   _|_ _| | | __
  / _ \ | '_ \| __| / __| |/ _` / __| '_ \    | |/ _` | | |/ /
 / ___ \| | | | |_| \__ \ | (_| \__ \ | | |   | | (_| | |   < 
/_/   \_\_| |_|\__|_|___/_|\__,_|___/_| |_|   |_|\__,_|_|_|\_\

EOF
echo -e "${NC}"
echo -e "${PURPLE}Script de DÃ©ploiement v6.0 - Multi-OS + HTTPS + Storage RLS${NC}"
echo -e "${BLUE}Compatible avec : Ubuntu, Debian, Fedora, CentOS, RHEL, Rocky Linux, AlmaLinux, Arch, Manjaro, Alpine${NC}"

# VÃ©rifier les permissions Docker
# Installation des outils si nÃ©cessaires
print_header "Installation des prÃ©requis"

# Installation de Docker si nÃ©cessaire
if ! command -v docker &> /dev/null; then
    print_info "Installation de Docker..."
    
    case $OS_TYPE in
        ubuntu|debian)
            # Installation Docker officielle
            $PACKAGE_UPDATE_CMD
            $PACKAGE_INSTALL_CMD ca-certificates curl gnupg
            sudo install -m 0755 -d /etc/apt/keyrings
            curl -fsSL https://download.docker.com/linux/$OS_TYPE/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg
            sudo chmod a+r /etc/apt/keyrings/docker.gpg
            echo "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/$OS_TYPE $(. /etc/os-release && echo "$VERSION_CODENAME") stable" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null
            $PACKAGE_UPDATE_CMD
            $PACKAGE_INSTALL_CMD docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin
            ;;
        fedora|centos|rhel|rocky|almalinux)
            $PACKAGE_INSTALL_CMD yum-utils
            sudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo
            $PACKAGE_INSTALL_CMD docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin
            sudo systemctl start docker
            sudo systemctl enable docker
            ;;
        arch|manjaro)
            $PACKAGE_INSTALL_CMD docker docker-compose
            sudo systemctl start docker
            sudo systemctl enable docker
            ;;
        alpine)
            $PACKAGE_INSTALL_CMD docker docker-compose
            rc-service docker start
            rc-update add docker boot
            ;;
    esac
    
    # Ajouter l'utilisateur au groupe docker
    sudo usermod -aG docker $USER
    print_success "Docker installÃ©"
fi

# VÃ©rifier les autres outils
print_info "VÃ©rification des outils nÃ©cessaires..."
for tool in "${REQUIRED_TOOLS[@]}"; do
    if [ "$tool" = "docker" ]; then
        continue  # DÃ©jÃ  vÃ©rifiÃ©
    fi
    
    if ! command -v $tool &> /dev/null; then
        print_warning "Installation de $tool..."
        
        case $tool in
            jq)
                $PACKAGE_INSTALL_CMD jq
                ;;
            envsubst)
                case $OS_TYPE in
                    ubuntu|debian)
                        $PACKAGE_INSTALL_CMD gettext-base
                        ;;
                    *)
                        $PACKAGE_INSTALL_CMD gettext
                        ;;
                esac
                ;;
            git|openssl|curl)
                $PACKAGE_INSTALL_CMD $tool
                ;;
            *)
                print_error "Outil $tool non gÃ©rÃ© automatiquement"
                exit 1
                ;;
        esac
    else
        print_success "$tool âœ“"
    fi
done

# VÃ©rifier les permissions Docker
if ! docker ps >/dev/null 2>&1; then
    print_error "Permissions Docker manquantes"
    print_info "Ajout au groupe docker..."
    sudo usermod -aG docker $USER
    print_warning "Veuillez vous dÃ©connecter/reconnecter et relancer le script"
    exit 1
fi

print_header "Ã‰TAPE 1/13 : Configuration initiale"

# ============================================
# DÃ‰TECTION D'INSTALLATION EXISTANTE
# ============================================
EXISTING_INSTALL=false
KEEP_NGINX=false
PRESERVE_EXTRA_SERVICES=false

# DÃ©tecter nginx configurÃ©
if [ -f "/etc/nginx/sites-enabled/antislash-talk-ssl" ]; then
    EXISTING_INSTALL=true
    print_warning "Installation nginx existante dÃ©tectÃ©e !"
fi

# DÃ©tecter containers existants
EXISTING_CONTAINERS=$(docker ps -a --format '{{.Names}}' | grep -E "antislash|nocodb|n8n" || true)
if [ -n "$EXISTING_CONTAINERS" ]; then
    EXISTING_INSTALL=true
    print_warning "Containers existants dÃ©tectÃ©s :"
    echo "$EXISTING_CONTAINERS" | sed 's/^/  â€¢ /'
fi

# Si installation existante, proposer le mode UPDATE
if [ "$EXISTING_INSTALL" = "true" ]; then
    echo ""
    print_header "ğŸ”„ MODE DE DÃ‰PLOIEMENT"
    echo ""
    echo "Une installation existante a Ã©tÃ© dÃ©tectÃ©e."
    echo ""
    echo "Options disponibles :"
    echo "  1) UPDATE  - Mise Ã  jour (prÃ©serve nginx, SSL, services additionnels)"
    echo "  2) FRESH   - Installation complÃ¨te (âš ï¸  Ã‰CRASE TOUT)"
    echo ""
    read -p "Votre choix [1] : " DEPLOY_MODE
    DEPLOY_MODE=${DEPLOY_MODE:-1}
    
    if [ "$DEPLOY_MODE" = "1" ]; then
        print_success "Mode UPDATE sÃ©lectionnÃ©"
        KEEP_NGINX=true
        PRESERVE_EXTRA_SERVICES=true
        print_info "âœ… Nginx/SSL sera prÃ©servÃ©"
        print_info "âœ… Services additionnels (NocoDB, n8n) seront prÃ©servÃ©s"
        
        # DÃ©tecter les services additionnels
        EXTRA_SERVICES=""
        if docker ps -a --format '{{.Names}}' | grep -q "nocodb"; then
            EXTRA_SERVICES="$EXTRA_SERVICES nocodb"
            print_info "  â†’ NocoDB dÃ©tectÃ©"
        fi
        if docker ps -a --format '{{.Names}}' | grep -q "n8n"; then
            EXTRA_SERVICES="$EXTRA_SERVICES n8n"
            print_info "  â†’ n8n dÃ©tectÃ©"
        fi
    else
        print_warning "Mode FRESH sÃ©lectionnÃ© - Tout sera rÃ©installÃ©"
        KEEP_NGINX=false
        PRESERVE_EXTRA_SERVICES=false
    fi
fi

# VÃ©rifier si un .env.monorepo existe dÃ©jÃ 
if [ -f ".env.monorepo" ]; then
    print_warning "Un fichier .env.monorepo existe dÃ©jÃ "
    echo ""
    read -p "Voulez-vous le conserver et sauter la configuration ? (oui/non) [non] : " KEEP_ENV
    if [ "${KEEP_ENV}" = "oui" ] || [ "${KEEP_ENV}" = "o" ] || [ "${KEEP_ENV}" = "yes" ] || [ "${KEEP_ENV}" = "y" ]; then
        print_success "Conservation de .env.monorepo existant"
        print_info "Passage directement au dÃ©ploiement..."
        
        # Charger les variables existantes
        source .env.monorepo
        
        # Passer Ã  l'Ã©tape de dÃ©ploiement (ligne aprÃ¨s gÃ©nÃ©ration des clÃ©s)
        SKIP_CONFIG=true
    else
        print_info "Suppression de l'ancien .env.monorepo"
        rm -f .env.monorepo
        SKIP_CONFIG=false
    fi
else
    SKIP_CONFIG=false
fi

# Si on garde la config existante, sauter la configuration
if [ "$SKIP_CONFIG" = "true" ]; then
    print_info "Saut de la configuration interactive"
    # S'assurer que VPS_HOST est dÃ©fini
    if [ -z "$VPS_HOST" ]; then
        VPS_HOST=$(grep "^VPS_HOST=" .env.monorepo | cut -d= -f2 || echo "")
    fi
    # Extraire les variables nÃ©cessaires
    STUDIO_PASSWORD=$(grep "^STUDIO_PASSWORD=" .env.monorepo | cut -d= -f2 || generate_password)
    APP_USER_EMAIL=$(grep "^APP_USER_EMAIL=" .env.monorepo | cut -d= -f2 || echo "admin@antislash-talk.fr")
    APP_USER_PASSWORD=$(grep "^APP_USER_PASSWORD=" .env.monorepo | cut -d= -f2 || generate_password)
    
    print_success "Configuration chargÃ©e depuis .env.monorepo"
    
    # Passer directement Ã  l'Ã©tape 4 (build)
    GOTO_BUILD=true
else
    GOTO_BUILD=false
fi

# DÃ©tecter l'IP automatiquement
if [ "$GOTO_BUILD" != "true" ]; then
    print_info "DÃ©tection de l'IP du VPS..."
    DETECTED_IP=""

    # MÃ©thode 1: curl ifconfig.me (forcer IPv4)
    if [ -z "$DETECTED_IP" ]; then
        DETECTED_IP=$(curl -4 -s --max-time 5 ifconfig.me 2>/dev/null | grep -E '^[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}$' || true)
    fi

# MÃ©thode 2: curl ipinfo.io (forcer IPv4)
if [ -z "$DETECTED_IP" ]; then
    DETECTED_IP=$(curl -4 -s --max-time 5 ipinfo.io/ip 2>/dev/null | grep -E '^[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}$' || true)
fi

# MÃ©thode 3: curl checkip.amazonaws.com (forcer IPv4)
if [ -z "$DETECTED_IP" ]; then
    DETECTED_IP=$(curl -4 -s --max-time 5 checkip.amazonaws.com 2>/dev/null | grep -E '^[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}$' || true)
fi

# MÃ©thode 3bis: curl spÃ©cifique IPv4
if [ -z "$DETECTED_IP" ]; then
    DETECTED_IP=$(curl -4 -s --max-time 5 ipv4.icanhazip.com 2>/dev/null | tr -d '\n' || true)
fi

# MÃ©thode 4: ip addr show (IPv4 seulement)
if [ -z "$DETECTED_IP" ]; then
    DETECTED_IP=$(ip addr show | grep -oP '(?<=inet\s)\d+(\.\d+){3}' | grep -v '127.0.0.1' | grep -v '^172\.' | grep -v '^10\.' | grep -v '^192\.168\.' | head -1 || true)
fi

# MÃ©thode 5: hostname -I (IPv4 seulement)
if [ -z "$DETECTED_IP" ]; then
    DETECTED_IP=$(hostname -I | tr ' ' '\n' | grep -E '^[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}$' | grep -v '^127\.' | grep -v '^172\.' | grep -v '^10\.' | grep -v '^192\.168\.' | head -1 || true)
fi

# MÃ©thode 6: wget -qO- (en cas d'Ã©chec des autres)
if [ -z "$DETECTED_IP" ]; then
    DETECTED_IP=$(wget -qO- --timeout=5 http://ipv4.icanhazip.com 2>/dev/null | tr -d '\n' || true)
fi

# Valider que c'est bien une IPv4
if [ -n "$DETECTED_IP" ]; then
    # VÃ©rifier le format IPv4
    if echo "$DETECTED_IP" | grep -qE '^[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}$'; then
        print_success "IPv4 dÃ©tectÃ©e : $DETECTED_IP"
        read -p "IP ou domaine du VPS [$DETECTED_IP] : " VPS_HOST
        VPS_HOST=${VPS_HOST:-$DETECTED_IP}
    else
        print_warning "IP dÃ©tectÃ©e non valide (IPv6?) : $DETECTED_IP"
        print_info "Tentative de dÃ©tection IPv4 forcÃ©e..."
        
        # DerniÃ¨re tentative avec curl spÃ©cifique IPv4
        DETECTED_IP=$(curl -4 -s --max-time 5 api.ipify.org 2>/dev/null || true)
        
        if [ -n "$DETECTED_IP" ] && echo "$DETECTED_IP" | grep -qE '^[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}$'; then
            print_success "IPv4 trouvÃ©e : $DETECTED_IP"
            read -p "IP ou domaine du VPS [$DETECTED_IP] : " VPS_HOST
            VPS_HOST=${VPS_HOST:-$DETECTED_IP}
        else
            VPS_HOST=""
            while [ -z "$VPS_HOST" ]; do
                read -p "IP ou domaine du VPS (entrez votre IPv4) : " VPS_HOST
            done
        fi
    fi
else
    print_warning "Impossible de dÃ©tecter l'IP automatiquement"
    VPS_HOST=""
    while [ -z "$VPS_HOST" ]; do
        read -p "IP ou domaine du VPS : " VPS_HOST
    done
fi

# DÃ©tecter si c'est un domaine ou une IP
IS_DOMAIN=false
if echo "$VPS_HOST" | grep -qE '^[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}$'; then
    # Configuration IP (par dÃ©faut)
    print_info "Configuration avec IP : $VPS_HOST"
    APP_URL="https://${VPS_HOST}"
    API_URL="https://${VPS_HOST}:8443"
    STUDIO_URL="https://${VPS_HOST}:8444"
    OLLAMA_URL="https://${VPS_HOST}:8445"
    
    API_EXTERNAL_URL="https://${VPS_HOST}:8443"
    VITE_SUPABASE_URL="https://${VPS_HOST}:8443"
    VITE_OLLAMA_URL="https://${VPS_HOST}:8445"
    VITE_WHISPERX_URL="https://${VPS_HOST}/whisperx"
    VITE_PYTORCH_SERVICE_URL="https://${VPS_HOST}/pytorch"
else
    IS_DOMAIN=true
    print_info "Configuration avec domaine : $VPS_HOST"
    
    # Demander si on veut utiliser des sous-domaines
    read -p "Voulez-vous utiliser des sous-domaines ? (ex: app.$VPS_HOST, api.$VPS_HOST) [non] : " USE_SUBDOMAINS
    
    if [ "${USE_SUBDOMAINS}" = "oui" ] || [ "${USE_SUBDOMAINS}" = "o" ] || [ "${USE_SUBDOMAINS}" = "yes" ] || [ "${USE_SUBDOMAINS}" = "y" ]; then
        print_info "Configuration avec sous-domaines"
        APP_URL="https://app.${VPS_HOST}"
        API_URL="https://api.${VPS_HOST}"
        STUDIO_URL="https://studio.${VPS_HOST}"
        OLLAMA_URL="https://ollama.${VPS_HOST}"
        
        # Variables internes restent avec ports pour la configuration
        API_EXTERNAL_URL="https://api.${VPS_HOST}"
        VITE_SUPABASE_URL="https://api.${VPS_HOST}"
        VITE_OLLAMA_URL="https://ollama.${VPS_HOST}"
        VITE_WHISPERX_URL="https://app.${VPS_HOST}/whisperx"
        VITE_PYTORCH_SERVICE_URL="https://app.${VPS_HOST}/pytorch"
    else
        print_info "Configuration avec domaine unique et ports"
        APP_URL="https://${VPS_HOST}"
        API_URL="https://${VPS_HOST}:8443"
        STUDIO_URL="https://${VPS_HOST}:8444"
        OLLAMA_URL="https://${VPS_HOST}:8445"
        
        API_EXTERNAL_URL="https://${VPS_HOST}:8443"
        VITE_SUPABASE_URL="https://${VPS_HOST}:8443"
        VITE_OLLAMA_URL="https://${VPS_HOST}:8445"
        VITE_WHISPERX_URL="https://${VPS_HOST}/whisperx"
        VITE_PYTORCH_SERVICE_URL="https://${VPS_HOST}/pytorch"
    fi
fi

# Studio password
print_info "GÃ©nÃ©ration d'un mot de passe sÃ©curisÃ© pour Studio..."
GENERATED_STUDIO_PASSWORD=$(generate_password)
print_success "Mot de passe gÃ©nÃ©rÃ© : $GENERATED_STUDIO_PASSWORD"

read -sp "Mot de passe pour Supabase Studio [$GENERATED_STUDIO_PASSWORD] : " STUDIO_PASSWORD
echo
STUDIO_PASSWORD=${STUDIO_PASSWORD:-$GENERATED_STUDIO_PASSWORD}

# Email admin
read -p "Email de l'utilisateur admin [admin@antislash-talk.fr] : " APP_USER_EMAIL
APP_USER_EMAIL=${APP_USER_EMAIL:-admin@antislash-talk.fr}

# Mot de passe admin
print_info "GÃ©nÃ©ration d'un mot de passe sÃ©curisÃ© pour l'utilisateur admin..."
GENERATED_ADMIN_PASSWORD=$(generate_password)
print_success "Mot de passe gÃ©nÃ©rÃ© : $GENERATED_ADMIN_PASSWORD"

read -sp "Mot de passe pour l'utilisateur admin [$GENERATED_ADMIN_PASSWORD] : " APP_USER_PASSWORD
echo
APP_USER_PASSWORD=${APP_USER_PASSWORD:-$GENERATED_ADMIN_PASSWORD}

# Hide marketing pages
read -p "Masquer les pages marketing ? (oui/non) [oui] : " HIDE_MARKETING
VITE_HIDE_MARKETING_PAGES=$([ "${HIDE_MARKETING:-oui}" = "oui" ] && echo "true" || echo "false")

# HuggingFace token
read -p "Token HuggingFace (optionnel, EntrÃ©e pour ignorer) : " HUGGINGFACE_TOKEN

fi # Fin du if [ "$GOTO_BUILD" != "true" ]

print_header "Ã‰TAPE 2/13 : GÃ©nÃ©ration des clÃ©s et mots de passe"

# Si on saute la config, charger les clÃ©s depuis .env.monorepo
if [ "$GOTO_BUILD" = "true" ]; then
    print_info "Chargement des clÃ©s depuis .env.monorepo..."
    POSTGRES_PASSWORD=$(grep "^POSTGRES_PASSWORD=" .env.monorepo | cut -d= -f2)
    JWT_SECRET=$(grep "^JWT_SECRET=" .env.monorepo | cut -d= -f2)
    ANON_KEY=$(grep "^ANON_KEY=" .env.monorepo | cut -d= -f2)
    SERVICE_ROLE_KEY=$(grep "^SERVICE_ROLE_KEY=" .env.monorepo | cut -d= -f2)
    print_success "ClÃ©s chargÃ©es"
else

# GÃ©nÃ©rer toutes les clÃ©s nÃ©cessaires
POSTGRES_PASSWORD=$(generate_password)
JWT_SECRET=$(openssl rand -base64 64 | tr -d '\n')
ANON_KEY=""
SERVICE_ROLE_KEY=""

# GÃ©nÃ©rer les clÃ©s JWT avec le script Node.js
print_info "GÃ©nÃ©ration des clÃ©s JWT..."
cat > generate-jwt-keys.mjs << 'EOF'
import jwt from 'jsonwebtoken';

const jwtSecret = process.env.JWT_SECRET;
const expiresIn = '10y';

const anonPayload = {
  role: 'anon',
  iss: 'supabase',
  iat: Math.floor(Date.now() / 1000),
  exp: Math.floor(Date.now() / 1000) + (10 * 365 * 24 * 60 * 60)
};

const serviceRolePayload = {
  role: 'service_role',
  iss: 'supabase',
  iat: Math.floor(Date.now() / 1000),
  exp: Math.floor(Date.now() / 1000) + (10 * 365 * 24 * 60 * 60)
};

const anonKey = jwt.sign(anonPayload, jwtSecret);
const serviceRoleKey = jwt.sign(serviceRolePayload, jwtSecret);

console.log(`ANON_KEY=${anonKey}`);
console.log(`SERVICE_ROLE_KEY=${serviceRoleKey}`);
EOF

# Installer jsonwebtoken temporairement et gÃ©nÃ©rer les clÃ©s
print_info "Installation temporaire de jsonwebtoken..."
# Sauvegarder l'ancien package.json s'il existe
if [ -f "package.json" ]; then
    cp package.json package.json.backup
fi

# CrÃ©er un package.json propre pour l'installation
cat > package.json << 'PKGJSON'
{
  "type": "module",
  "dependencies": {
    "jsonwebtoken": "^9.0.0"
  }
}
PKGJSON

# Installer pour de vrai
npm install >/dev/null 2>&1

# ExÃ©cuter le script pour obtenir les clÃ©s
JWT_OUTPUT=$(JWT_SECRET="$JWT_SECRET" node generate-jwt-keys.mjs 2>&1)
JWT_EXIT_CODE=$?

# VÃ©rifier que Ã§a a fonctionnÃ©
if [ $JWT_EXIT_CODE -ne 0 ] || [ -z "$JWT_OUTPUT" ] || echo "$JWT_OUTPUT" | grep -q "Error"; then
    print_error "Erreur lors de la gÃ©nÃ©ration des clÃ©s JWT"
    echo "$JWT_OUTPUT"
    exit 1
fi

ANON_KEY=$(echo "$JWT_OUTPUT" | grep "ANON_KEY=" | cut -d'=' -f2-)
SERVICE_ROLE_KEY=$(echo "$JWT_OUTPUT" | grep "SERVICE_ROLE_KEY=" | cut -d'=' -f2-)

# VÃ©rifier que les clÃ©s ont bien Ã©tÃ© gÃ©nÃ©rÃ©es
if [ -z "$ANON_KEY" ] || [ -z "$SERVICE_ROLE_KEY" ]; then
    print_error "Les clÃ©s JWT n'ont pas pu Ãªtre extraites"
    echo "JWT_OUTPUT:"
    echo "$JWT_OUTPUT"
    exit 1
fi

# Nettoyer
rm -f generate-jwt-keys.mjs
rm -rf node_modules package-lock.json

# Restaurer l'ancien package.json s'il existait
if [ -f "package.json.backup" ]; then
    mv package.json.backup package.json
else
    rm -f package.json
fi

print_success "ClÃ©s gÃ©nÃ©rÃ©es avec succÃ¨s"

fi # Fin du else (gÃ©nÃ©ration des clÃ©s)

print_header "Ã‰TAPE 3/13 : CrÃ©ation du fichier .env.monorepo"

# Si on a gardÃ© la config, skip cette Ã©tape aussi
if [ "$GOTO_BUILD" = "true" ]; then
    print_info "Fichier .env.monorepo dÃ©jÃ  existant, Ã©tape ignorÃ©e"
else

# CrÃ©er le fichier .env.monorepo avec toutes les variables
cat > .env.monorepo << EOF
# Configuration de base
NODE_ENV=production
VPS_HOST=${VPS_HOST}
API_EXTERNAL_URL=${API_EXTERNAL_URL}
VITE_SUPABASE_URL=${VITE_SUPABASE_URL}
VITE_SUPABASE_ANON_KEY=${ANON_KEY}
VITE_HIDE_MARKETING_PAGES=${VITE_HIDE_MARKETING_PAGES}
VITE_OLLAMA_URL=${VITE_OLLAMA_URL}
VITE_WHISPERX_URL=${VITE_WHISPERX_URL}

# PostgreSQL
POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
POSTGRES_HOST=db
POSTGRES_PORT=5432
POSTGRES_DB=postgres

# JWT
JWT_SECRET=${JWT_SECRET}
ANON_KEY=${ANON_KEY}
SERVICE_ROLE_KEY=${SERVICE_ROLE_KEY}

# URLs des services
SUPABASE_URL=http://${VPS_HOST}:54321
PUBLIC_REST_URL=http://${VPS_HOST}:54321/rest/v1/
PGRST_JWT_SECRET=${JWT_SECRET}

# Auth Service (GoTrue)
GOTRUE_SITE_URL=http://${VPS_HOST}
GOTRUE_URI_ALLOW_LIST=http://${VPS_HOST}:*,http://${VPS_HOST}
GOTRUE_JWT_SECRET=${JWT_SECRET}
GOTRUE_JWT_EXP=3600
GOTRUE_JWT_DEFAULT_GROUP_NAME=authenticated
GOTRUE_DB_DRIVER=postgres
DATABASE_URL=postgres://supabase_auth_admin:${POSTGRES_PASSWORD}@db:5432/postgres

# Studio
STUDIO_DEFAULT_ORGANIZATION="Antislash Talk"
STUDIO_DEFAULT_PROJECT=Production
STUDIO_PORT=3000
STUDIO_PROXY_PORT=54327
SUPABASE_PUBLIC_URL=http://${VPS_HOST}:54321
NEXT_PUBLIC_ENABLE_LOGS=true
NEXT_ANALYTICS_BACKEND_PROVIDER=postgres

# Storage
STORAGE_BACKEND=file
STORAGE_FILE_BACKEND_PATH=/var/lib/storage
STORAGE_S3_BUCKET=
STORAGE_S3_ENDPOINT=
STORAGE_S3_FORCE_PATH_STYLE=
STORAGE_S3_PROTOCOL=
STORAGE_S3_REGION=

# Email (Local)
GOTRUE_SMTP_HOST=inbucket
GOTRUE_SMTP_PORT=2500
GOTRUE_SMTP_USER=
GOTRUE_SMTP_PASS=
GOTRUE_SMTP_SENDER_NAME="Antislash Talk"

# Configuration utilisateur
APP_USER_EMAIL=${APP_USER_EMAIL}
APP_USER_PASSWORD=${APP_USER_PASSWORD}

# Kong
KONG_HTTP2_MAX_FIELD_SIZE=16384
KONG_HTTP2_MAX_HEADER_SIZE=16384

# Dashboard
DASHBOARD_USERNAME=antislash
DASHBOARD_PASSWORD=${STUDIO_PASSWORD}

# Studio Auth
STUDIO_USER=antislash
STUDIO_PASSWORD=${STUDIO_PASSWORD}

# AI Services
HUGGINGFACE_TOKEN=${HUGGINGFACE_TOKEN}
OLLAMA_BASE_URL=http://ollama:11434
VITE_OLLAMA_BASE_URL=http://${VPS_HOST}:11434

# Imgproxy
IMGPROXY_ENABLE_WEBP_DETECTION=true
EOF

print_success "Configuration crÃ©Ã©e"

fi # Fin du else (crÃ©ation de .env.monorepo)

print_header "Ã‰TAPE 4/13 : ArrÃªt des services existants"

# ArrÃªter et nettoyer les services existants
if [ "$PRESERVE_EXTRA_SERVICES" = "true" ]; then
    print_info "Mode UPDATE : ArrÃªt sÃ©lectif des containers Antislash uniquement"
    
    # ArrÃªter uniquement les containers antislash-talk-*
    ANTISLASH_CONTAINERS=$(docker ps -a --format '{{.Names}}' | grep "^antislash-talk-" || true)
    if [ -n "$ANTISLASH_CONTAINERS" ]; then
        echo "$ANTISLASH_CONTAINERS" | while read container; do
            print_info "ArrÃªt de $container"
            docker stop "$container" 2>/dev/null || true
            docker rm "$container" 2>/dev/null || true
        done
    fi
    
    # NE PAS faire down -v pour prÃ©server les volumes et services additionnels
    print_success "Services Antislash arrÃªtÃ©s, services additionnels prÃ©servÃ©s"
    
    # Liste des services prÃ©servÃ©s
    PRESERVED=$(docker ps --format '{{.Names}}' | grep -E "nocodb|n8n" || true)
    if [ -n "$PRESERVED" ]; then
        print_info "Services additionnels toujours actifs :"
        echo "$PRESERVED" | sed 's/^/  âœ… /'
    fi
else
    print_info "ArrÃªt complet de tous les services"
    docker compose -f docker-compose.monorepo.yml down -v --remove-orphans || true
fi

# Nettoyage Docker lÃ©ger
docker system prune -f

print_header "Ã‰TAPE 5/13 : Construction de l'image web"

print_info "CrÃ©ation du fichier apps/web/.env pour le build..."
cat > apps/web/.env << EOF
VITE_SUPABASE_URL=${VITE_SUPABASE_URL}
VITE_SUPABASE_ANON_KEY=${ANON_KEY}
VITE_HIDE_MARKETING_PAGES=${VITE_HIDE_MARKETING_PAGES}
VITE_OLLAMA_URL=${VITE_OLLAMA_URL}
VITE_WHISPERX_URL=${VITE_WHISPERX_URL}
VITE_PYTORCH_SERVICE_URL=${VITE_PYTORCH_SERVICE_URL}
EOF

print_info "Export des variables pour le build..."
export API_EXTERNAL_URL="${API_EXTERNAL_URL}"
export VITE_SUPABASE_URL="${VITE_SUPABASE_URL}"
export VITE_SUPABASE_ANON_KEY="$ANON_KEY"
export VITE_HIDE_MARKETING_PAGES="$VITE_HIDE_MARKETING_PAGES"
export VITE_OLLAMA_URL="${VITE_OLLAMA_URL}"
export VITE_PYTORCH_SERVICE_URL="${VITE_PYTORCH_SERVICE_URL}"

print_info "Construction de l'image web..."
docker compose -f docker-compose.monorepo.yml --env-file .env.monorepo build \
  --build-arg VITE_SUPABASE_URL="${VITE_SUPABASE_URL}" \
  --build-arg VITE_SUPABASE_ANON_KEY="${ANON_KEY}" \
  --build-arg VITE_HIDE_MARKETING_PAGES="${VITE_HIDE_MARKETING_PAGES}" \
  --build-arg VITE_OLLAMA_URL="${VITE_OLLAMA_URL}" \
  --build-arg VITE_WHISPERX_URL="${VITE_WHISPERX_URL}" \
  --build-arg VITE_PYTORCH_SERVICE_URL="${VITE_PYTORCH_SERVICE_URL}" \
  web

print_header "Ã‰TAPE 6/13 : DÃ©marrage de PostgreSQL"

print_info "DÃ©marrage de PostgreSQL seul..."
docker compose -f docker-compose.monorepo.yml --env-file .env.monorepo up -d db

# Attendre que PostgreSQL soit prÃªt
print_info "Attente de PostgreSQL..."
POSTGRES_READY=false
for i in {1..30}; do
    if docker exec antislash-talk-db pg_isready -U postgres > /dev/null 2>&1; then
        POSTGRES_READY=true
        break
    fi
    sleep 2
done

if [ "$POSTGRES_READY" = false ]; then
    print_error "PostgreSQL n'a pas dÃ©marrÃ©"
    exit 1
fi

print_success "PostgreSQL prÃªt"
sleep 5

print_header "Ã‰TAPE 7/13 : Configuration de PostgreSQL"

print_info "Configuration complÃ¨te de PostgreSQL..."
docker exec -i antislash-talk-db psql -U postgres << EOF
-- Configuration
ALTER SYSTEM SET password_encryption = 'scram-sha-256';
SELECT pg_reload_conf();

-- CrÃ©ation des schÃ©mas
CREATE SCHEMA IF NOT EXISTS auth;
CREATE SCHEMA IF NOT EXISTS storage;
CREATE SCHEMA IF NOT EXISTS extensions;
CREATE SCHEMA IF NOT EXISTS public;

-- Extensions (avec gestion d'erreur)
DO \$\$
BEGIN
    CREATE EXTENSION IF NOT EXISTS "uuid-ossp" WITH SCHEMA extensions CASCADE;
EXCEPTION
    WHEN others THEN
        RAISE NOTICE 'Extension uuid-ossp: %', SQLERRM;
END \$\$;

DO \$\$
BEGIN
    CREATE EXTENSION IF NOT EXISTS pgcrypto WITH SCHEMA extensions CASCADE;
EXCEPTION
    WHEN others THEN
        RAISE NOTICE 'Extension pgcrypto: %', SQLERRM;
END \$\$;

-- Types ENUM pour GoTrue MFA (DOIVENT Ãªtre dans public, pas auth !)
DO \$\$ 
BEGIN
    -- factor_type dans public
    IF NOT EXISTS (SELECT 1 FROM pg_type WHERE typname = 'factor_type' AND typnamespace = (SELECT oid FROM pg_namespace WHERE nspname = 'public')) THEN
        CREATE TYPE factor_type AS ENUM ('totp', 'webauthn', 'phone');
    END IF;
    
    -- factor_status dans public
    IF NOT EXISTS (SELECT 1 FROM pg_type WHERE typname = 'factor_status' AND typnamespace = (SELECT oid FROM pg_namespace WHERE nspname = 'public')) THEN
        CREATE TYPE factor_status AS ENUM ('unverified', 'verified');
    END IF;
    
    -- aal_level dans public
    IF NOT EXISTS (SELECT 1 FROM pg_type WHERE typname = 'aal_level' AND typnamespace = (SELECT oid FROM pg_namespace WHERE nspname = 'public')) THEN
        CREATE TYPE aal_level AS ENUM ('aal1', 'aal2', 'aal3');
    END IF;
END \$\$;

-- Table auth.schema_migrations
CREATE TABLE IF NOT EXISTS auth.schema_migrations (
    version text NOT NULL PRIMARY KEY
);

-- CrÃ©ation et configuration des rÃ´les avec EXECUTE format pour Ã©viter les erreurs de syntaxe
DO \$\$
DECLARE
    db_password text := '${POSTGRES_PASSWORD}';
BEGIN
    -- postgres
    EXECUTE format('ALTER ROLE postgres PASSWORD %L', db_password);
    
    -- supabase_auth_admin (SUPERUSER pour Ã©viter les problÃ¨mes de permissions)
    IF NOT EXISTS (SELECT 1 FROM pg_roles WHERE rolname = 'supabase_auth_admin') THEN
        CREATE ROLE supabase_auth_admin;
    END IF;
    EXECUTE format('ALTER ROLE supabase_auth_admin WITH SUPERUSER CREATEDB CREATEROLE LOGIN PASSWORD %L', db_password);
    
    -- supabase_storage_admin (SUPERUSER aussi)
    IF NOT EXISTS (SELECT 1 FROM pg_roles WHERE rolname = 'supabase_storage_admin') THEN
        CREATE ROLE supabase_storage_admin;
    END IF;
    EXECUTE format('ALTER ROLE supabase_storage_admin WITH SUPERUSER CREATEDB CREATEROLE LOGIN PASSWORD %L', db_password);
    
    -- authenticator
    IF NOT EXISTS (SELECT 1 FROM pg_roles WHERE rolname = 'authenticator') THEN
        CREATE ROLE authenticator;
    END IF;
    EXECUTE format('ALTER ROLE authenticator WITH LOGIN PASSWORD %L', db_password);
    
    -- service_role
    IF NOT EXISTS (SELECT 1 FROM pg_roles WHERE rolname = 'service_role') THEN
        CREATE ROLE service_role;
    END IF;
    ALTER ROLE service_role WITH NOLOGIN;
    
    -- anon
    IF NOT EXISTS (SELECT 1 FROM pg_roles WHERE rolname = 'anon') THEN
        CREATE ROLE anon;
    END IF;
    ALTER ROLE anon WITH NOLOGIN;
    
    -- supabase_admin
    IF NOT EXISTS (SELECT 1 FROM pg_roles WHERE rolname = 'supabase_admin') THEN
        CREATE ROLE supabase_admin;
    END IF;
    EXECUTE format('ALTER ROLE supabase_admin WITH SUPERUSER CREATEDB CREATEROLE LOGIN PASSWORD %L', db_password);
END \$\$;

-- Permissions et ownership
ALTER SCHEMA auth OWNER TO supabase_auth_admin;
ALTER SCHEMA storage OWNER TO supabase_storage_admin;
ALTER TABLE auth.schema_migrations OWNER TO supabase_auth_admin;

-- CRITIQUE: Configurer le search_path pour supabase_auth_admin
ALTER ROLE supabase_auth_admin SET search_path TO auth, public, extensions;

GRANT ALL PRIVILEGES ON SCHEMA auth TO supabase_auth_admin;
GRANT ALL PRIVILEGES ON SCHEMA storage TO supabase_storage_admin;
GRANT ALL PRIVILEGES ON SCHEMA public TO postgres, supabase_admin;
GRANT ALL PRIVILEGES ON DATABASE postgres TO supabase_admin, supabase_auth_admin, supabase_storage_admin;
GRANT USAGE ON SCHEMA auth TO authenticator;
GRANT USAGE ON SCHEMA storage TO authenticator;
GRANT USAGE ON SCHEMA public TO authenticator, anon, service_role;
GRANT USAGE ON SCHEMA extensions TO postgres, supabase_admin, supabase_auth_admin, supabase_storage_admin;
GRANT anon TO authenticator;
GRANT service_role TO authenticator;

SELECT 'PostgreSQL configurÃ©' as status;
EOF

# Configurer pg_hba.conf
print_info "Configuration de pg_hba.conf..."
docker exec antislash-talk-db bash -c "cat > /var/lib/postgresql/data/pg_hba.conf << 'EOF'
# TYPE  DATABASE        USER            ADDRESS                 METHOD
local   all             all                                     trust
host    all             all             127.0.0.1/32            scram-sha-256
host    all             all             ::1/128                 scram-sha-256
host    all             all             0.0.0.0/0               scram-sha-256
host    all             all             ::/0                    scram-sha-256
EOF"

docker exec antislash-talk-db psql -U postgres -c "SELECT pg_reload_conf();"
print_success "PostgreSQL configurÃ©"

print_header "Ã‰TAPE 8/13 : Application des migrations et dÃ©marrage des services"

# Appliquer les migrations
print_info "Application des migrations..."
for migration in packages/supabase/migrations/*.sql; do
    if [ -f "$migration" ]; then
        filename=$(basename "$migration")
        if docker exec -i antislash-talk-db psql -U postgres -d postgres < "$migration" 2>/dev/null; then
            print_success "Migration appliquÃ©e : $filename"
        else
            print_info "Migration dÃ©jÃ  appliquÃ©e ou non nÃ©cessaire : $filename"
        fi
    fi
done

# DÃ©marrer tous les services
print_info "DÃ©marrage de tous les services..."
docker compose -f docker-compose.monorepo.yml --env-file .env.monorepo up -d

# Attendre que les services critiques soient prÃªts
print_info "Attente du dÃ©marrage des services..."

# VÃ©rifier que Auth est prÃªt
print_info "VÃ©rification du service Auth..."
AUTH_READY=false
for i in {1..30}; do
    if docker exec antislash-talk-auth curl -f http://localhost:9999/health 2>/dev/null | grep -q "ok"; then
        AUTH_READY=true
        print_success "Service Auth prÃªt"
        break
    fi
    sleep 2
done

if [ "$AUTH_READY" = false ]; then
    print_warning "Service Auth pas encore prÃªt aprÃ¨s 60s, on continue quand mÃªme..."
fi

# VÃ©rifier que Storage est prÃªt
print_info "VÃ©rification du service Storage..."
STORAGE_READY=false
for i in {1..30}; do
    if docker exec antislash-talk-storage curl -f http://localhost:5000/status 2>/dev/null | grep -q "ok"; then
        STORAGE_READY=true
        print_success "Service Storage prÃªt"
        break
    fi
    sleep 2
done

if [ "$STORAGE_READY" = false ]; then
    print_warning "Service Storage pas encore prÃªt aprÃ¨s 60s, on continue quand mÃªme..."
fi

# Attendre encore un peu pour la stabilisation
print_info "Attente de stabilisation (15s)..."
sleep 15

# ============================================
# OPTIONAL: WhisperX Service
# ============================================
print_header "Service Optionnel : WhisperX"

echo ""
echo "WhisperX est un service de transcription ultra-rapide avec diarization (identification des locuteurs)."
echo "  âš¡ Performances : 6x plus rapide que PyTorch"
echo "  ğŸ­ Diarization : Identification native des locuteurs"
echo "  ğŸ’¾ Ressources  : ~3GB RAM, CPU intensif"
echo ""
echo "Note : L'application fonctionne sans WhisperX (fallback sur PyTorch ou Gemini)"
echo ""

read -p "Voulez-vous activer WhisperX ? (oui/non) [non] : " ENABLE_WHISPERX
ENABLE_WHISPERX=${ENABLE_WHISPERX:-non}

WHISPERX_ENABLED=false

if [ "$ENABLE_WHISPERX" = "oui" ] || [ "$ENABLE_WHISPERX" = "o" ] || [ "$ENABLE_WHISPERX" = "yes" ] || [ "$ENABLE_WHISPERX" = "y" ]; then
    print_info "ğŸ—ï¸  Build de l'image WhisperX (cela peut prendre 5-10 minutes)..."
    
    if docker compose -f docker-compose.monorepo.yml build whisperx; then
        print_success "Image WhisperX construite avec succÃ¨s"
        
        print_info "ğŸš€ DÃ©marrage du service WhisperX..."
        if docker compose -f docker-compose.monorepo.yml --env-file .env.monorepo --profile whisperx up -d; then
            print_success "Service WhisperX dÃ©marrÃ©"
            
            # VÃ©rifier que WhisperX est prÃªt
            print_info "VÃ©rification du service WhisperX (jusqu'Ã  60s)..."
            WHISPERX_READY=false
            for i in {1..30}; do
                if docker exec antislash-talk-whisperx curl -f http://localhost:8082/health 2>/dev/null | grep -q "ok"; then
                    WHISPERX_READY=true
                    WHISPERX_ENABLED=true
                    print_success "âœ… Service WhisperX opÃ©rationnel !"
                    break
                fi
                sleep 2
            done
            
            if [ "$WHISPERX_READY" = false ]; then
                print_warning "âš ï¸  WhisperX n'est pas encore prÃªt (peut prendre plus de temps au premier dÃ©marrage)"
                print_info "VÃ©rifiez les logs : docker compose -f docker-compose.monorepo.yml logs whisperx"
                WHISPERX_ENABLED=true  # On le marque quand mÃªme comme activÃ©
            fi
        else
            print_error "âŒ Ã‰chec du dÃ©marrage de WhisperX"
            print_warning "L'application fonctionnera quand mÃªme sans WhisperX"
        fi
    else
        print_error "âŒ Ã‰chec du build de WhisperX"
        print_warning "L'application fonctionnera quand mÃªme sans WhisperX"
    fi
else
    print_info "WhisperX non activÃ© (peut Ãªtre activÃ© plus tard)"
    print_info "Commande : docker compose -f docker-compose.monorepo.yml --profile whisperx up -d"
fi

# ============================================
# OPTIONAL: PyTorch Service
# ============================================
print_header "Service Optionnel : PyTorch Transcription"

echo ""
echo "PyTorch Transcription est un service avec Whisper V3 + Diarization (pyannote.audio)."
echo "  ğŸ™ï¸  ModÃ¨le : OpenAI Whisper V3 (trÃ¨s prÃ©cis)"
echo "  ğŸ­ Diarization : pyannote.audio (identification des locuteurs)"
echo "  ğŸ’¾ Ressources  : ~2GB RAM, CPU/GPU"
echo ""
echo "Comparaison :"
echo "  â€¢ WhisperX : Plus rapide (6x), diarization intÃ©grÃ©e"
echo "  â€¢ PyTorch  : Plus prÃ©cis, modÃ¨les officiels OpenAI"
echo ""
echo "Note : L'application fonctionne sans PyTorch (fallback sur Gemini ou WhisperX si activÃ©)"
echo ""

read -p "Voulez-vous activer PyTorch Transcription ? (oui/non) [non] : " ENABLE_PYTORCH
ENABLE_PYTORCH=${ENABLE_PYTORCH:-non}

PYTORCH_ENABLED=false

if [ "$ENABLE_PYTORCH" = "oui" ] || [ "$ENABLE_PYTORCH" = "o" ] || [ "$ENABLE_PYTORCH" = "yes" ] || [ "$ENABLE_PYTORCH" = "y" ]; then
    print_info "ğŸ—ï¸  Build de l'image PyTorch (cela peut prendre 5-10 minutes)..."
    
    if docker compose -f docker-compose.monorepo.yml build transcription-pytorch; then
        print_success "Image PyTorch construite avec succÃ¨s"
        
        print_info "ğŸš€ DÃ©marrage du service PyTorch..."
        if docker compose -f docker-compose.monorepo.yml --env-file .env.monorepo --profile pytorch up -d; then
            print_success "Service PyTorch dÃ©marrÃ©"
            
            # VÃ©rifier que PyTorch est prÃªt
            print_info "VÃ©rification du service PyTorch (jusqu'Ã  60s)..."
            PYTORCH_READY=false
            for i in {1..30}; do
                if docker exec antislash-talk-transcription curl -f http://localhost:8000/health 2>/dev/null | grep -q "ok"; then
                    PYTORCH_READY=true
                    PYTORCH_ENABLED=true
                    print_success "âœ… Service PyTorch opÃ©rationnel !"
                    break
                fi
                sleep 2
            done
            
            if [ "$PYTORCH_READY" = false ]; then
                print_warning "âš ï¸  PyTorch n'est pas encore prÃªt (peut prendre plus de temps au premier dÃ©marrage)"
                print_info "Le service tÃ©lÃ©charge les modÃ¨les Whisper (~1.5GB au premier lancement)"
                print_info "VÃ©rifiez les logs : docker compose -f docker-compose.monorepo.yml logs transcription-pytorch"
                PYTORCH_ENABLED=true  # On le marque quand mÃªme comme activÃ©
            fi
        else
            print_error "âŒ Ã‰chec du dÃ©marrage de PyTorch"
            print_warning "L'application fonctionnera quand mÃªme sans PyTorch"
        fi
    else
        print_error "âŒ Ã‰chec du build de PyTorch"
        print_warning "L'application fonctionnera quand mÃªme sans PyTorch"
    fi
else
    print_info "PyTorch non activÃ© (peut Ãªtre activÃ© plus tard)"
    print_info "Commande : docker compose -f docker-compose.monorepo.yml --profile pytorch up -d"
fi

# CRITIQUE: Mettre Ã  jour Kong avec les bonnes clÃ©s
print_info "Mise Ã  jour de Kong avec les clÃ©s JWT..."

# ArrÃªter Kong temporairement
docker stop antislash-talk-kong

# CrÃ©er le nouveau fichier kong.yml avec les bonnes clÃ©s
cp packages/supabase/kong.yml packages/supabase/kong.yml.backup
sed -i "s/ANON_KEY_PLACEHOLDER/${ANON_KEY}/g" packages/supabase/kong.yml
sed -i "s/SERVICE_ROLE_KEY_PLACEHOLDER/${SERVICE_ROLE_KEY}/g" packages/supabase/kong.yml

# RedÃ©marrer Kong qui va charger le nouveau fichier
docker start antislash-talk-kong

# Attendre que Kong soit prÃªt
sleep 5
print_success "Kong mis Ã  jour avec les nouvelles clÃ©s"

# Restaurer le template pour les prochains dÃ©ploiements
mv packages/supabase/kong.yml.backup packages/supabase/kong.yml 2>/dev/null || true

print_header "Ã‰TAPE 9/13 : Configuration Nginx HTTPS"

# Si mode UPDATE et nginx existe, on skip cette Ã©tape
if [ "$KEEP_NGINX" = "true" ] && [ -f "/etc/nginx/sites-enabled/antislash-talk-ssl" ]; then
    print_success "Configuration Nginx existante prÃ©servÃ©e âœ…"
    print_info "Fichier : /etc/nginx/sites-enabled/antislash-talk-ssl"
    
    # VÃ©rifier si Let's Encrypt est configurÃ©
    if grep -q "letsencrypt" /etc/nginx/sites-enabled/antislash-talk-ssl; then
        print_success "Certificats Let's Encrypt dÃ©tectÃ©s âœ…"
    elif [ -f "/etc/nginx/ssl/selfsigned.crt" ]; then
        print_info "Certificats auto-signÃ©s utilisÃ©s"
    fi
    
    # VÃ©rifier si WhisperX est dans la config
    if grep -q "whisperx" /etc/nginx/sites-enabled/antislash-talk-ssl; then
        print_success "Route WhisperX dÃ©tectÃ©e dans nginx âœ…"
    else
        print_warning "Route WhisperX non trouvÃ©e dans nginx"
        print_info "Pour l'ajouter, consulter: nginx-secure-ssl.conf"
    fi
    
    # Recharger nginx pour Ãªtre sÃ»r
    print_info "Rechargement de nginx..."
    sudo nginx -t && sudo systemctl reload nginx
    
    SKIP_NGINX_CONFIG=true
else
    SKIP_NGINX_CONFIG=false
    
    print_info "Installation de Nginx si nÃ©cessaire..."
    if ! command -v nginx &> /dev/null; then
        $PACKAGE_UPDATE_CMD
        
        # Installation selon l'OS
        case $OS_TYPE in
            ubuntu|debian)
                $PACKAGE_INSTALL_CMD nginx
                ;;
            fedora|centos|rhel|rocky|almalinux)
                $PACKAGE_INSTALL_CMD nginx
                sudo systemctl enable nginx
                ;;
            arch|manjaro)
                $PACKAGE_INSTALL_CMD nginx
                sudo systemctl enable nginx
                ;;
            alpine)
                $PACKAGE_INSTALL_CMD nginx
                rc-update add nginx default
                ;;
        esac
    fi
    
    print_info "GÃ©nÃ©ration des certificats SSL auto-signÃ©s..."
    sudo mkdir -p /etc/nginx/ssl
    if [ ! -f /etc/nginx/ssl/selfsigned.crt ]; then
        sudo openssl req -x509 -nodes -days 365 -newkey rsa:2048 \
            -keyout /etc/nginx/ssl/selfsigned.key \
            -out /etc/nginx/ssl/selfsigned.crt \
            -subj "/C=FR/ST=France/L=Paris/O=Antislash/CN=${VPS_HOST}"
        print_success "Certificats SSL gÃ©nÃ©rÃ©s"
    else
        print_info "Certificats SSL dÃ©jÃ  existants"
    fi
    
    print_info "Configuration de Nginx pour HTTPS..."
fi

# Skip Ã©criture config si mode UPDATE
if [ "$SKIP_NGINX_CONFIG" = "true" ]; then
    print_info "Configuration nginx non modifiÃ©e (mode UPDATE)"
else
    # Configuration diffÃ©rente selon domaine ou IP
    if [ "$IS_DOMAIN" = "true" ] && ([ "${USE_SUBDOMAINS}" = "oui" ] || [ "${USE_SUBDOMAINS}" = "o" ] || [ "${USE_SUBDOMAINS}" = "yes" ] || [ "${USE_SUBDOMAINS}" = "y" ]); then
        print_info "Configuration Nginx avec sous-domaines..."
        
        # Utiliser le template avec sous-domaines
        if [ -f "nginx-subdomains-ssl.conf" ]; then
            print_info "Utilisation du template nginx-subdomains-ssl.conf"
            
            # DÃ©terminer les certificats SSL Ã  utiliser
            if [ -f "/etc/letsencrypt/live/${VPS_HOST}/fullchain.pem" ]; then
                SSL_CERT="/etc/letsencrypt/live/${VPS_HOST}/fullchain.pem"
                SSL_KEY="/etc/letsencrypt/live/${VPS_HOST}/privkey.pem"
                SSL_TRUSTED="/etc/letsencrypt/live/${VPS_HOST}/chain.pem"
                print_success "Certificats Let's Encrypt dÃ©tectÃ©s"
            else
                SSL_CERT="/etc/nginx/ssl/selfsigned.crt"
                SSL_KEY="/etc/nginx/ssl/selfsigned.key"
                SSL_TRUSTED="/etc/nginx/ssl/selfsigned.crt"
                print_info "Utilisation des certificats auto-signÃ©s"
            fi
            
            # Copier et adapter le template
            sed -e "s|riquelme-talk.antislash.studio|${VPS_HOST}|g" \
                -e "s|/etc/letsencrypt/live/riquelme-talk.antislash.studio/fullchain.pem|${SSL_CERT}|g" \
                -e "s|/etc/letsencrypt/live/riquelme-talk.antislash.studio/privkey.pem|${SSL_KEY}|g" \
                -e "s|/etc/letsencrypt/live/riquelme-talk.antislash.studio/chain.pem|${SSL_TRUSTED}|g" \
                nginx-subdomains-ssl.conf | sudo tee /etc/nginx/sites-available/antislash-talk-ssl > /dev/null
            
            print_success "Configuration nginx avec sous-domaines appliquÃ©e"
        else
            print_warning "Template nginx-subdomains-ssl.conf non trouvÃ©, gÃ©nÃ©ration basique"
            
    # Configuration avec sous-domaines (app, api, studio, ollama) - FALLBACK
    sudo tee /etc/nginx/sites-available/antislash-talk-ssl > /dev/null << NGINXCONF
# Redirection HTTP vers HTTPS
server {
    listen 80;
    server_name app.${VPS_HOST} api.${VPS_HOST} studio.${VPS_HOST} ollama.${VPS_HOST};
    return 301 https://\$host\$request_uri;
}

# Application Web (app.domain.com)
server {
    listen 443 ssl http2;
    server_name app.${VPS_HOST};

    ssl_certificate /etc/nginx/ssl/selfsigned.crt;
    ssl_certificate_key /etc/nginx/ssl/selfsigned.key;
    ssl_protocols TLSv1.2 TLSv1.3;
    ssl_ciphers HIGH:!aNULL:!MD5;

    location / {
        proxy_pass http://localhost:3000;
        proxy_http_version 1.1;
        proxy_set_header Upgrade \$http_upgrade;
        proxy_set_header Connection 'upgrade';
        proxy_set_header Host \$host;
        proxy_set_header X-Real-IP \$remote_addr;
        proxy_set_header X-Forwarded-For \$proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto \$scheme;
        proxy_cache_bypass \$http_upgrade;
    }
}

# API Supabase (api.domain.com)
server {
    listen 443 ssl http2;
    server_name api.${VPS_HOST};

    ssl_certificate /etc/nginx/ssl/selfsigned.crt;
    ssl_certificate_key /etc/nginx/ssl/selfsigned.key;
    ssl_protocols TLSv1.2 TLSv1.3;
    ssl_ciphers HIGH:!aNULL:!MD5;

    client_max_body_size 100M;

    location / {
        proxy_pass http://localhost:54321;
        proxy_http_version 1.1;
        proxy_set_header Upgrade \$http_upgrade;
        proxy_set_header Connection 'upgrade';
        proxy_set_header Host \$host;
        proxy_set_header X-Real-IP \$remote_addr;
        proxy_set_header X-Forwarded-For \$proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto \$scheme;
        proxy_cache_bypass \$http_upgrade;
        proxy_read_timeout 300s;
        proxy_connect_timeout 75s;
    }
}

# Studio Supabase (studio.domain.com)
server {
    listen 443 ssl http2;
    server_name studio.${VPS_HOST};

    ssl_certificate /etc/nginx/ssl/selfsigned.crt;
    ssl_certificate_key /etc/nginx/ssl/selfsigned.key;
    ssl_protocols TLSv1.2 TLSv1.3;
    ssl_ciphers HIGH:!aNULL:!MD5;

    location / {
        proxy_pass http://localhost:54327;
        proxy_http_version 1.1;
        proxy_set_header Upgrade \$http_upgrade;
        proxy_set_header Connection 'upgrade';
        proxy_set_header Host \$host;
        proxy_set_header X-Real-IP \$remote_addr;
        proxy_set_header X-Forwarded-For \$proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto \$scheme;
        proxy_cache_bypass \$http_upgrade;
    }
}

# Ollama API (ollama.domain.com)
server {
    listen 443 ssl http2;
    server_name ollama.${VPS_HOST};

    ssl_certificate /etc/nginx/ssl/selfsigned.crt;
    ssl_certificate_key /etc/nginx/ssl/selfsigned.key;
    ssl_protocols TLSv1.2 TLSv1.3;
    ssl_ciphers HIGH:!aNULL:!MD5;

    client_max_body_size 500M;
    proxy_read_timeout 600s;
    proxy_connect_timeout 600s;

    location / {
        # Headers CORS
        if (\$request_method = 'OPTIONS') {
            add_header 'Access-Control-Allow-Origin' '*' always;
            add_header 'Access-Control-Allow-Methods' 'GET, POST, PUT, DELETE, OPTIONS' always;
            add_header 'Access-Control-Allow-Headers' 'DNT,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Range,Authorization' always;
            add_header 'Access-Control-Max-Age' 1728000;
            add_header 'Content-Type' 'text/plain; charset=utf-8';
            add_header 'Content-Length' 0;
            return 204;
        }

        add_header 'Access-Control-Allow-Origin' '*' always;
        add_header 'Access-Control-Allow-Methods' 'GET, POST, PUT, DELETE, OPTIONS' always;
        add_header 'Access-Control-Allow-Headers' 'DNT,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Range,Authorization' always;

        proxy_pass http://localhost:11434;
        proxy_http_version 1.1;
        proxy_set_header Upgrade \$http_upgrade;
        proxy_set_header Connection 'upgrade';
        proxy_set_header Host \$host;
        proxy_set_header X-Real-IP \$remote_addr;
        proxy_set_header X-Forwarded-For \$proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto \$scheme;
        proxy_cache_bypass \$http_upgrade;
    }
}
NGINXCONF
        fi  # Fin du if template nginx-subdomains-ssl.conf
        
    else
        print_info "Configuration Nginx standard (avec ports)..."
        
        # Utiliser le template avec ports si disponible
        if [ -f "nginx-secure-ssl.conf" ]; then
            print_info "Utilisation du template nginx-secure-ssl.conf"
            
            # DÃ©terminer les certificats SSL Ã  utiliser
            if [ -f "/etc/letsencrypt/live/${VPS_HOST}/fullchain.pem" ]; then
                SSL_CERT="/etc/letsencrypt/live/${VPS_HOST}/fullchain.pem"
                SSL_KEY="/etc/letsencrypt/live/${VPS_HOST}/privkey.pem"
                SSL_TRUSTED="/etc/letsencrypt/live/${VPS_HOST}/chain.pem"
                print_success "Certificats Let's Encrypt dÃ©tectÃ©s"
            else
                SSL_CERT="/etc/nginx/ssl/selfsigned.crt"
                SSL_KEY="/etc/nginx/ssl/selfsigned.key"
                SSL_TRUSTED="/etc/nginx/ssl/selfsigned.crt"
                print_info "Utilisation des certificats auto-signÃ©s"
            fi
            
            # Copier et adapter le template
            sed -e "s|riquelme-talk.antislash.studio|${VPS_HOST}|g" \
                -e "s|/etc/letsencrypt/live/riquelme-talk.antislash.studio/fullchain.pem|${SSL_CERT}|g" \
                -e "s|/etc/letsencrypt/live/riquelme-talk.antislash.studio/privkey.pem|${SSL_KEY}|g" \
                -e "s|/etc/letsencrypt/live/riquelme-talk.antislash.studio/chain.pem|${SSL_TRUSTED}|g" \
                nginx-secure-ssl.conf | sudo tee /etc/nginx/sites-available/antislash-talk-ssl > /dev/null
            
            print_success "Configuration nginx avec ports appliquÃ©e"
        else
            print_warning "Template nginx-secure-ssl.conf non trouvÃ©, gÃ©nÃ©ration basique"
            
    sudo tee /etc/nginx/sites-available/antislash-talk-ssl > /dev/null << 'NGINXCONF'
# Redirection HTTP vers HTTPS
server {
    listen 80;
    server_name _;
    return 301 https://$host$request_uri;
}

# Application Web (HTTPS sur 443)
server {
    listen 443 ssl http2;
    server_name _;

    ssl_certificate /etc/nginx/ssl/selfsigned.crt;
    ssl_certificate_key /etc/nginx/ssl/selfsigned.key;
    ssl_protocols TLSv1.2 TLSv1.3;
    ssl_ciphers HIGH:!aNULL:!MD5;

    location / {
        proxy_pass http://localhost:3000;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection 'upgrade';
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        proxy_cache_bypass $http_upgrade;
    }
}

# API Supabase (HTTPS sur 8443)
server {
    listen 8443 ssl http2;
    server_name _;

    ssl_certificate /etc/nginx/ssl/selfsigned.crt;
    ssl_certificate_key /etc/nginx/ssl/selfsigned.key;
    ssl_protocols TLSv1.2 TLSv1.3;
    ssl_ciphers HIGH:!aNULL:!MD5;

    client_max_body_size 100M;

    location / {
        proxy_pass http://localhost:54321;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection 'upgrade';
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        proxy_cache_bypass $http_upgrade;
        proxy_read_timeout 300s;
        proxy_connect_timeout 75s;
    }
}

# Studio Supabase (HTTPS sur 8444)
server {
    listen 8444 ssl http2;
    server_name _;

    ssl_certificate /etc/nginx/ssl/selfsigned.crt;
    ssl_certificate_key /etc/nginx/ssl/selfsigned.key;
    ssl_protocols TLSv1.2 TLSv1.3;
    ssl_ciphers HIGH:!aNULL:!MD5;

    location / {
        proxy_pass http://localhost:54327;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection 'upgrade';
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        proxy_cache_bypass $http_upgrade;
    }
}

# Ollama API (HTTPS sur 8445)
server {
    listen 8445 ssl http2;
    server_name _;

    ssl_certificate /etc/nginx/ssl/selfsigned.crt;
    ssl_certificate_key /etc/nginx/ssl/selfsigned.key;
    ssl_protocols TLSv1.2 TLSv1.3;
    ssl_ciphers HIGH:!aNULL:!MD5;

    client_max_body_size 500M;
    proxy_read_timeout 600s;
    proxy_connect_timeout 600s;

    location / {
        proxy_pass http://localhost:11434;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection 'upgrade';
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        proxy_cache_bypass $http_upgrade;
    }
}
NGINXCONF
        fi  # Fin du if template nginx-secure-ssl.conf
    fi  # Fin du if sous-domaines vs ports

    # Activer le site
    sudo ln -sf /etc/nginx/sites-available/antislash-talk-ssl /etc/nginx/sites-enabled/
    sudo rm -f /etc/nginx/sites-enabled/default
    
    # Tester et recharger Nginx
    print_info "Test de la configuration Nginx..."
    if sudo nginx -t; then
        print_success "Configuration Nginx valide"
        sudo systemctl reload nginx
        print_success "Nginx rechargÃ© avec HTTPS"
    else
        print_error "Erreur dans la configuration Nginx"
        exit 1
    fi
fi # Fin du bloc SKIP_NGINX_CONFIG

print_header "Ã‰TAPE 10/13 : CrÃ©ation des donnÃ©es initiales"

# Attendre que les tables existent (crÃ©Ã©es par les migrations)
print_info "Attente de la crÃ©ation des tables par les migrations..."
TABLES_READY=false
for i in {1..30}; do
    AUTH_EXISTS=$(docker exec antislash-talk-db psql -U postgres -t -c "SELECT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'auth' AND table_name = 'users');" | tr -d ' ')
    STORAGE_EXISTS=$(docker exec antislash-talk-db psql -U postgres -t -c "SELECT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'storage' AND table_name = 'buckets');" | tr -d ' ')
    PROFILES_EXISTS=$(docker exec antislash-talk-db psql -U postgres -t -c "SELECT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'profiles');" | tr -d ' ')
    
    if [ "$AUTH_EXISTS" = "t" ] && [ "$STORAGE_EXISTS" = "t" ] && [ "$PROFILES_EXISTS" = "t" ]; then
        TABLES_READY=true
        print_success "Toutes les tables nÃ©cessaires sont crÃ©Ã©es (auth.users, storage.buckets, public.profiles)"
        break
    fi
    sleep 2
done

if [ "$TABLES_READY" = true ]; then
    print_success "Tables crÃ©Ã©es, ajout des donnÃ©es initiales..."
    
    docker exec -i antislash-talk-db psql -U postgres << EOF
-- DÃ©sactiver temporairement RLS
ALTER TABLE auth.users DISABLE ROW LEVEL SECURITY;
ALTER TABLE auth.identities DISABLE ROW LEVEL SECURITY;
ALTER TABLE storage.buckets DISABLE ROW LEVEL SECURITY;
ALTER TABLE public.profiles DISABLE ROW LEVEL SECURITY;

-- CrÃ©er l'utilisateur admin (seulement s'il n'existe pas dÃ©jÃ )
DO \$\$
DECLARE
    v_user_id uuid;
    v_user_email text := '${APP_USER_EMAIL}';
BEGIN
    -- VÃ©rifier si l'utilisateur existe dÃ©jÃ 
    SELECT id INTO v_user_id FROM auth.users WHERE email = v_user_email;
    
    IF v_user_id IS NULL THEN
        -- CrÃ©er l'utilisateur
        INSERT INTO auth.users (
            id,
            email,
            encrypted_password,
            email_confirmed_at,
            created_at,
            updated_at,
            instance_id,
            aud,
            role,
            raw_app_meta_data,
            raw_user_meta_data
        ) VALUES (
            extensions.gen_random_uuid(),
            v_user_email,
            extensions.crypt('${APP_USER_PASSWORD}', extensions.gen_salt('bf', 6)),
            now(),
            now(),
            now(),
            '00000000-0000-0000-0000-000000000000',
            'authenticated',
            'authenticated',
            '{"provider": "email", "providers": ["email"]}',
            '{}'
        ) RETURNING id INTO v_user_id;
        
        -- CrÃ©er l'identitÃ©
        INSERT INTO auth.identities (
            id,
            user_id,
            provider_id,
            provider,
            identity_data,
            last_sign_in_at,
            created_at,
            updated_at
        ) VALUES (
            extensions.gen_random_uuid(),
            v_user_id,
            v_user_id::text,
            'email',
            json_build_object('sub', v_user_id::text, 'email', v_user_email)::jsonb,
            now(),
            now(),
            now()
        );
        
        RAISE NOTICE 'Utilisateur crÃ©Ã©: %', v_user_email;
    ELSE
        RAISE NOTICE 'Utilisateur existe dÃ©jÃ : %', v_user_email;
    END IF;
END \$\$;

-- CrÃ©er le profil pour l'utilisateur admin
INSERT INTO public.profiles (id, email, full_name, role)
SELECT id, email, email, 'admin'
FROM auth.users
WHERE email = '${APP_USER_EMAIL}'
ON CONFLICT (id) DO UPDATE SET 
    email = EXCLUDED.email,
    role = 'admin',
    updated_at = now();

-- CRITIQUE: Corriger les colonnes NULL en auth.users (GoTrue attend des strings vides, pas NULL)
UPDATE auth.users SET 
    email_change = COALESCE(email_change, ''),
    email_change_token_new = COALESCE(email_change_token_new, ''),
    email_change_token_current = COALESCE(email_change_token_current, ''),
    confirmation_token = COALESCE(confirmation_token, ''),
    recovery_token = COALESCE(recovery_token, ''),
    phone_change = COALESCE(phone_change, ''),
    phone_change_token = COALESCE(phone_change_token, '')
WHERE email_change IS NULL 
   OR email_change_token_new IS NULL 
   OR email_change_token_current IS NULL
   OR confirmation_token IS NULL
   OR recovery_token IS NULL
   OR phone_change IS NULL
   OR phone_change_token IS NULL;

-- DÃ©finir DEFAULT '' pour Ã©viter les NULL futurs
ALTER TABLE auth.users ALTER COLUMN email_change SET DEFAULT '';
ALTER TABLE auth.users ALTER COLUMN email_change_token_new SET DEFAULT '';
ALTER TABLE auth.users ALTER COLUMN email_change_token_current SET DEFAULT '';
ALTER TABLE auth.users ALTER COLUMN confirmation_token SET DEFAULT '';
ALTER TABLE auth.users ALTER COLUMN recovery_token SET DEFAULT '';
ALTER TABLE auth.users ALTER COLUMN phone_change SET DEFAULT '';
ALTER TABLE auth.users ALTER COLUMN phone_change_token SET DEFAULT '';

-- Note: Les tables (profiles, meetings, api_keys, user_api_keys, etc.) sont crÃ©Ã©es par les migrations
-- Ne pas les crÃ©er manuellement ici pour Ã©viter les conflits

-- CrÃ©er tous les buckets nÃ©cessaires (selon base locale rÃ©elle)
INSERT INTO storage.buckets (id, name, public, file_size_limit, allowed_mime_types, created_at, updated_at)
VALUES 
  ('avatars', 'avatars', true, NULL, NULL, now(), now()),
  ('meeting-audio', 'meeting-audio', true, NULL, NULL, now(), now()),
  ('meetingrecordings', 'meetingrecordings', true, NULL, NULL, now(), now()),
  ('reports', 'reports', false, NULL, NULL, now(), now()),
  ('transcriptions', 'transcriptions', false, NULL, NULL, now(), now())
ON CONFLICT (id) DO NOTHING;

-- Configurer les permissions Storage pour que tous les services puissent accÃ©der
GRANT USAGE ON SCHEMA storage TO postgres, anon, authenticated, service_role, supabase_storage_admin;
GRANT ALL ON ALL TABLES IN SCHEMA storage TO postgres, service_role, supabase_storage_admin;
GRANT ALL ON ALL SEQUENCES IN SCHEMA storage TO postgres, service_role, supabase_storage_admin;
GRANT ALL ON ALL TABLES IN SCHEMA storage TO authenticated;
GRANT ALL ON ALL SEQUENCES IN SCHEMA storage TO authenticated;
ALTER DEFAULT PRIVILEGES FOR ROLE postgres IN SCHEMA storage GRANT ALL ON TABLES TO authenticated, supabase_storage_admin;
ALTER DEFAULT PRIVILEGES FOR ROLE postgres IN SCHEMA storage GRANT ALL ON SEQUENCES TO authenticated, supabase_storage_admin;

-- RÃ©activer RLS avec FORCE pour s'assurer que les policies s'appliquent
ALTER TABLE auth.users ENABLE ROW LEVEL SECURITY;
ALTER TABLE auth.identities ENABLE ROW LEVEL SECURITY;
ALTER TABLE public.profiles ENABLE ROW LEVEL SECURITY;
ALTER TABLE storage.buckets FORCE ROW LEVEL SECURITY;
ALTER TABLE storage.objects FORCE ROW LEVEL SECURITY;

-- CrÃ©er les policies RLS
DO \$\$
BEGIN
    -- Policies pour auth.users
    DROP POLICY IF EXISTS "Users can view own profile" ON auth.users;
    CREATE POLICY "Users can view own profile" 
    ON auth.users FOR SELECT 
    USING (auth.uid() = id);
    
    -- Policies pour public.profiles
    DROP POLICY IF EXISTS "Service role bypass profiles" ON public.profiles;
    CREATE POLICY "Service role bypass profiles"
    ON public.profiles FOR ALL
    TO service_role, postgres
    USING (true)
    WITH CHECK (true);
    
    DROP POLICY IF EXISTS "Users can view own profile" ON public.profiles;
    CREATE POLICY "Users can view own profile"
    ON public.profiles FOR SELECT
    TO authenticated
    USING (auth.uid() = id);
    
    DROP POLICY IF EXISTS "Users can update own profile" ON public.profiles;
    CREATE POLICY "Users can update own profile"
    ON public.profiles FOR UPDATE
    TO authenticated
    USING (auth.uid() = id)
    WITH CHECK (auth.uid() = id);
    
    DROP POLICY IF EXISTS "Users can insert own profile" ON public.profiles;
    CREATE POLICY "Users can insert own profile"
    ON public.profiles FOR INSERT
    TO authenticated
    WITH CHECK (auth.uid() = id);
    
    -- Policies pour api_keys
    DROP POLICY IF EXISTS "Service role bypass api keys" ON public.api_keys;
    CREATE POLICY "Service role bypass api keys"
    ON public.api_keys FOR ALL
    TO service_role, postgres
    USING (true)
    WITH CHECK (true);
    
    DROP POLICY IF EXISTS "Users can manage own api keys" ON public.api_keys;
    CREATE POLICY "Users can manage own api keys"
    ON public.api_keys FOR ALL
    TO authenticated
    USING (user_id = auth.uid())
    WITH CHECK (user_id = auth.uid());
    
    -- Policies pour user_api_keys
    DROP POLICY IF EXISTS "Service role bypass user api keys" ON public.user_api_keys;
    CREATE POLICY "Service role bypass user api keys"
    ON public.user_api_keys FOR ALL
    TO service_role, postgres
    USING (true)
    WITH CHECK (true);
    
    DROP POLICY IF EXISTS "Users can manage own user api keys" ON public.user_api_keys;
    CREATE POLICY "Users can manage own user api keys"
    ON public.user_api_keys FOR ALL
    TO authenticated
    USING (user_id = auth.uid())
    WITH CHECK (user_id = auth.uid());
    
    -- Policies pour meetings
    DROP POLICY IF EXISTS "Service role bypass meetings" ON public.meetings;
    CREATE POLICY "Service role bypass meetings"
    ON public.meetings FOR ALL
    TO service_role, postgres
    USING (true)
    WITH CHECK (true);
    
    DROP POLICY IF EXISTS "Users can manage own meetings" ON public.meetings;
    CREATE POLICY "Users can manage own meetings"
    ON public.meetings FOR ALL
    TO authenticated
    USING (user_id = auth.uid())
    WITH CHECK (user_id = auth.uid());
    
    -- Policies pour storage.buckets
    DROP POLICY IF EXISTS "Service role bypass" ON storage.buckets;
    CREATE POLICY "Service role bypass" 
    ON storage.buckets FOR ALL 
    TO service_role, postgres
    USING (true)
    WITH CHECK (true);
    
    DROP POLICY IF EXISTS "Authenticated users can view buckets" ON storage.buckets;
    CREATE POLICY "Authenticated users can view buckets" 
    ON storage.buckets FOR SELECT 
    TO authenticated
    USING (true);
    
    -- Policies pour storage.objects
    IF EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'storage' AND table_name = 'objects') THEN
        -- Service role bypass pour tous les objets (CRITIQUE pour Storage service)
        DROP POLICY IF EXISTS "Service role bypass" ON storage.objects;
        DROP POLICY IF EXISTS "service_role_all" ON storage.objects;
        CREATE POLICY "service_role_all" 
        ON storage.objects FOR ALL 
        TO service_role, postgres, supabase_storage_admin
        USING (true)
        WITH CHECK (true);
        
        -- Nettoyer les anciennes policies
        DROP POLICY IF EXISTS "Users can upload to recordings" ON storage.objects;
        DROP POLICY IF EXISTS "Users can view own recordings" ON storage.objects;
        DROP POLICY IF EXISTS "Users can delete own recordings" ON storage.objects;
        DROP POLICY IF EXISTS "Public buckets are viewable" ON storage.objects;
        DROP POLICY IF EXISTS "Authenticated users can upload" ON storage.objects;
        DROP POLICY IF EXISTS "Authenticated users can select" ON storage.objects;
        DROP POLICY IF EXISTS "Authenticated users can delete" ON storage.objects;
        DROP POLICY IF EXISTS "authenticated_insert_all" ON storage.objects;
        DROP POLICY IF EXISTS "authenticated_select_all" ON storage.objects;
        DROP POLICY IF EXISTS "authenticated_update_all" ON storage.objects;
        DROP POLICY IF EXISTS "authenticated_delete_all" ON storage.objects;
        DROP POLICY IF EXISTS "anon_select_public" ON storage.objects;
        
        -- Policies ULTRA-PERMISSIVES pour authenticated (pas de vÃ©rification de bucket ou UUID)
        CREATE POLICY "authenticated_insert_all" 
        ON storage.objects FOR INSERT 
        TO authenticated
        WITH CHECK (true);

        CREATE POLICY "authenticated_select_all" 
        ON storage.objects FOR SELECT 
        TO authenticated
        USING (true);

        CREATE POLICY "authenticated_update_all" 
        ON storage.objects FOR UPDATE 
        TO authenticated
        USING (true)
        WITH CHECK (true);

        CREATE POLICY "authenticated_delete_all" 
        ON storage.objects FOR DELETE 
        TO authenticated
        USING (true);
        
        -- Public buckets viewable by anon
        CREATE POLICY "anon_select_public"
        ON storage.objects FOR SELECT
        TO anon
        USING (bucket_id IN (SELECT id FROM storage.buckets WHERE public = TRUE));
    END IF;
END \$\$;

SELECT 'DonnÃ©es initiales crÃ©Ã©es' as status;
EOF
else
    print_warning "Les tables n'ont pas Ã©tÃ© crÃ©Ã©es automatiquement"
fi

print_header "Ã‰TAPE 11/13 : VÃ©rification du dÃ©ploiement"

# VÃ©rifier l'Ã©tat des services
print_info "Ã‰tat des services :"
docker compose -f docker-compose.monorepo.yml ps

# VÃ©rifier les donnÃ©es crÃ©Ã©es avec diagnostic
print_info "VÃ©rification des donnÃ©es crÃ©Ã©es..."

USERS_COUNT=$(docker exec antislash-talk-db psql -U postgres -t -c "SELECT count(*) FROM auth.users;" 2>/dev/null | tr -d ' ')
PROFILES_COUNT=$(docker exec antislash-talk-db psql -U postgres -t -c "SELECT count(*) FROM public.profiles;" 2>/dev/null | tr -d ' ')
BUCKETS_COUNT=$(docker exec antislash-talk-db psql -U postgres -t -c "SELECT count(*) FROM storage.buckets;" 2>/dev/null | tr -d ' ')

echo ""
echo "ğŸ“Š RÃ©sultats de la vÃ©rification :"
echo "  - Utilisateurs (auth.users) : ${USERS_COUNT:-0}"
echo "  - Profils (public.profiles) : ${PROFILES_COUNT:-0}"
echo "  - Buckets (storage.buckets) : ${BUCKETS_COUNT:-0}"
echo ""

# VÃ©rifier si tout est OK
DEPLOYMENT_OK=true

if [ "${USERS_COUNT:-0}" -eq 0 ]; then
    print_error "âŒ PROBLÃˆME : Aucun utilisateur crÃ©Ã© dans auth.users"
    DEPLOYMENT_OK=false
    echo "   â†’ Diagnostic :"
    docker logs antislash-talk-auth --tail 20 2>&1 | grep -i error || echo "     Pas d'erreur Ã©vidente dans les logs Auth"
fi

if [ "${PROFILES_COUNT:-0}" -eq 0 ]; then
    print_error "âŒ PROBLÃˆME : Aucun profil crÃ©Ã© dans public.profiles"
    DEPLOYMENT_OK=false
    echo "   â†’ VÃ©rification : La table profiles existe-t-elle ?"
    docker exec antislash-talk-db psql -U postgres -t -c "\d public.profiles" 2>&1 | head -5
fi

if [ "${BUCKETS_COUNT:-0}" -eq 0 ]; then
    print_error "âŒ PROBLÃˆME : Aucun bucket crÃ©Ã© dans storage.buckets"
    DEPLOYMENT_OK=false
    echo "   â†’ Diagnostic :"
    docker logs antislash-talk-storage --tail 20 2>&1 | grep -i error || echo "     Pas d'erreur Ã©vidente dans les logs Storage"
fi

# Afficher les dÃ©tails si tout est OK
if [ "$DEPLOYMENT_OK" = true ]; then
    print_success "âœ… Toutes les vÃ©rifications sont OK !"
    echo ""
    print_info "DÃ©tails des donnÃ©es crÃ©Ã©es :"
    docker exec antislash-talk-db psql -U postgres -c "
SELECT 'Utilisateurs' as type, count(*) as count, string_agg(email, ', ') as details FROM auth.users
UNION ALL
SELECT 'Buckets' as type, count(*) as count, string_agg(name, ', ') as details FROM storage.buckets;"
fi

# Configuration Nginx pour Studio
print_info "Configuration de l'authentification Studio..."

# Nettoyer le fichier local s'il existe comme rÃ©pertoire
if [ -d "studio.htpasswd" ]; then
    rm -rf studio.htpasswd
fi

# GÃ©nÃ©rer le hash du mot de passe
STUDIO_PASSWORD_HASH=$(docker run --rm httpd:alpine htpasswd -nbB antislash "$STUDIO_PASSWORD" | cut -d: -f2)

# CrÃ©er le fichier .htpasswd directement dans le container (pas de montage de volume)
docker exec antislash-talk-studio-proxy sh -c "echo 'antislash:$STUDIO_PASSWORD_HASH' > /etc/nginx/.htpasswd && chmod 644 /etc/nginx/.htpasswd"

# VÃ©rifier que c'est bien un fichier
if docker exec antislash-talk-studio-proxy test -f /etc/nginx/.htpasswd; then
    print_success "Fichier .htpasswd crÃ©Ã© correctement dans le container"
    # Recharger nginx
    docker exec antislash-talk-studio-proxy nginx -s reload
else
    print_error "Erreur: .htpasswd n'a pas Ã©tÃ© crÃ©Ã© correctement"
    # Essayer de redÃ©marrer le container
    docker restart antislash-talk-studio-proxy
fi

# Afficher les informations finales
print_header "Ã‰TAPE 12/13 : Configuration Ollama"

print_info "Attente du dÃ©marrage d'Ollama (30s)..."
sleep 30

# VÃ©rifier si Ollama est accessible
if docker exec antislash-talk-ollama curl -s http://localhost:11434/api/tags >/dev/null 2>&1; then
    print_success "Ollama est accessible"
    
    # VÃ©rifier si des modÃ¨les sont installÃ©s
    MODELS_COUNT=$(docker exec antislash-talk-ollama ollama list 2>/dev/null | grep -c "^[a-zA-Z]" || echo "0")
    
    if [ "$MODELS_COUNT" -eq "0" ]; then
        print_info "Aucun modÃ¨le Ollama trouvÃ©. Installation de llama3.2:3b..."
        if docker exec -it antislash-talk-ollama ollama pull llama3.2:3b; then
            print_success "ModÃ¨le llama3.2:3b installÃ©"
        else
            print_warning "Impossible d'installer le modÃ¨le automatiquement"
            print_info "Vous pourrez l'installer plus tard avec : ./install-ollama-model.sh"
        fi
    else
        print_success "$MODELS_COUNT modÃ¨le(s) Ollama dÃ©jÃ  installÃ©(s)"
    fi
else
    print_warning "Ollama n'est pas encore prÃªt"
    print_info "Vous pourrez installer un modÃ¨le plus tard avec : ./install-ollama-model.sh"
fi

print_header "Ã‰TAPE 13/13 : Configuration CORS pour Ollama"

print_info "Configuration des headers CORS pour Ollama..."

# CrÃ©er la configuration Nginx avec CORS pour Ollama
cat > /tmp/nginx-ollama-cors.conf << 'NGINXCORS'
# Ollama API (HTTPS sur 8445)
server {
    listen 8445 ssl http2;
    server_name _;

    ssl_certificate /etc/nginx/ssl/selfsigned.crt;
    ssl_certificate_key /etc/nginx/ssl/selfsigned.key;
    ssl_protocols TLSv1.2 TLSv1.3;
    ssl_ciphers HIGH:!aNULL:!MD5;

    client_max_body_size 500M;
    proxy_read_timeout 600s;
    proxy_connect_timeout 600s;

    location / {
        # Headers CORS permissifs
        if ($request_method = 'OPTIONS') {
            add_header 'Access-Control-Allow-Origin' '*' always;
            add_header 'Access-Control-Allow-Methods' 'GET, POST, PUT, DELETE, OPTIONS' always;
            add_header 'Access-Control-Allow-Headers' 'DNT,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Range,Authorization' always;
            add_header 'Access-Control-Max-Age' 1728000;
            add_header 'Content-Type' 'text/plain; charset=utf-8';
            add_header 'Content-Length' 0;
            return 204;
        }

        add_header 'Access-Control-Allow-Origin' '*' always;
        add_header 'Access-Control-Allow-Methods' 'GET, POST, PUT, DELETE, OPTIONS' always;
        add_header 'Access-Control-Allow-Headers' 'DNT,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Range,Authorization' always;
        add_header 'Access-Control-Expose-Headers' 'Content-Length,Content-Range' always;

        proxy_pass http://localhost:11434;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection 'upgrade';
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        proxy_cache_bypass $http_upgrade;
        proxy_buffering off;
        proxy_request_buffering off;
    }
}
NGINXCORS

# Remplacer la configuration Ollama dans Nginx
if [ -f "/etc/nginx/sites-available/antislash-talk-ssl" ]; then
    sudo cp /etc/nginx/sites-available/antislash-talk-ssl /etc/nginx/sites-available/antislash-talk-ssl.backup
    sudo sed -i '/# Ollama API/,/^}$/d' /etc/nginx/sites-available/antislash-talk-ssl
    cat /tmp/nginx-ollama-cors.conf | sudo tee -a /etc/nginx/sites-available/antislash-talk-ssl > /dev/null
    print_success "Configuration Nginx mise Ã  jour avec CORS pour Ollama"
    sudo systemctl reload nginx
fi

rm -f /tmp/nginx-ollama-cors.conf

print_header "ğŸ‰ DÃ‰PLOIEMENT TERMINÃ‰ AVEC SUCCÃˆS !"

echo -e "${GREEN}â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—${NC}"
echo -e "${GREEN}â•‘                     INFORMATIONS D'ACCÃˆS                       â•‘${NC}"
echo -e "${GREEN}â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£${NC}"
echo -e "${GREEN}â•‘${NC} Application Web    : ${CYAN}${APP_URL}${NC}"
echo -e "${GREEN}â•‘${NC} Supabase Studio    : ${CYAN}${STUDIO_URL}${NC}"
echo -e "${GREEN}â•‘${NC}   Utilisateur      : ${YELLOW}antislash${NC}"
echo -e "${GREEN}â•‘${NC}   Mot de passe     : ${YELLOW}${STUDIO_PASSWORD}${NC}"
echo -e "${GREEN}â•‘${NC}"
echo -e "${GREEN}â•‘${NC} API Supabase       : ${CYAN}${API_URL}${NC}"
echo -e "${GREEN}â•‘${NC} Ollama API         : ${CYAN}${OLLAMA_URL}${NC}"

# Services optionnels de transcription
if [ "$WHISPERX_ENABLED" = true ]; then
    WHISPERX_PORT="8082"
    if [ "$IS_DOMAIN" = "true" ]; then
        WHISPERX_URL="http://${VPS_HOST}:${WHISPERX_PORT}"
    else
        WHISPERX_URL="http://${VPS_HOST}:${WHISPERX_PORT}"
    fi
    echo -e "${GREEN}â•‘${NC} WhisperX API       : ${CYAN}${WHISPERX_URL} âš¡${NC}"
fi

if [ "$PYTORCH_ENABLED" = true ]; then
    PYTORCH_PORT="8000"
    if [ "$IS_DOMAIN" = "true" ]; then
        PYTORCH_URL="http://${VPS_HOST}:${PYTORCH_PORT}"
    else
        PYTORCH_URL="http://${VPS_HOST}:${PYTORCH_PORT}"
    fi
    echo -e "${GREEN}â•‘${NC} PyTorch API        : ${CYAN}${PYTORCH_URL} ğŸ™ï¸${NC}"
fi

echo -e "${GREEN}â•‘${NC}"
echo -e "${GREEN}â•‘${NC} Compte Admin App   :"
echo -e "${GREEN}â•‘${NC}   Email            : ${YELLOW}${APP_USER_EMAIL}${NC}"
echo -e "${GREEN}â•‘${NC}   Mot de passe     : ${YELLOW}${APP_USER_PASSWORD}${NC}"
if [ -n "$HUGGINGFACE_TOKEN" ]; then
echo -e "${GREEN}â•‘${NC} HuggingFace Token  : ${YELLOW}${HUGGINGFACE_TOKEN:0:10}...${NC}"
fi
echo -e "${GREEN}â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"

print_info "Toutes les informations ont Ã©tÃ© sauvegardÃ©es dans deployment-info.txt"

# Afficher une note sur le DNS si on utilise des sous-domaines
if [ "$IS_DOMAIN" = "true" ] && ([ "${USE_SUBDOMAINS}" = "oui" ] || [ "${USE_SUBDOMAINS}" = "o" ] || [ "${USE_SUBDOMAINS}" = "yes" ] || [ "${USE_SUBDOMAINS}" = "y" ]); then
    echo ""
    print_warning "IMPORTANT : Configuration DNS requise !"
    echo ""
    echo "Vous devez configurer les enregistrements DNS suivants :"
    echo "  - app.${VPS_HOST}    â†’ ${DETECTED_IP:-VOTRE_IP}"
    echo "  - api.${VPS_HOST}    â†’ ${DETECTED_IP:-VOTRE_IP}"
    echo "  - studio.${VPS_HOST} â†’ ${DETECTED_IP:-VOTRE_IP}"
    echo "  - ollama.${VPS_HOST} â†’ ${DETECTED_IP:-VOTRE_IP}"
    echo ""
    echo "Pour Let's Encrypt (certificats SSL valides), exÃ©cutez aprÃ¨s configuration DNS :"
    echo "  sudo certbot --nginx -d app.${VPS_HOST} -d api.${VPS_HOST} -d studio.${VPS_HOST} -d ollama.${VPS_HOST}"
fi

# Sauvegarder les informations
cat > deployment-info.txt << EOF
DÃ©ploiement Antislash Talk - $(date)
=====================================

URLs d'accÃ¨s :
- Application : ${APP_URL}
- Studio : ${STUDIO_URL} (user: antislash, pass: ${STUDIO_PASSWORD})
- API : ${API_URL}
- Ollama : ${OLLAMA_URL}
EOF

if [ "$WHISPERX_ENABLED" = true ]; then
    echo "- WhisperX : ${WHISPERX_URL}" >> deployment-info.txt
fi

if [ "$PYTORCH_ENABLED" = true ]; then
    echo "- PyTorch : ${PYTORCH_URL}" >> deployment-info.txt
fi

cat >> deployment-info.txt << EOF

Compte admin :
- Email : ${APP_USER_EMAIL}
- Mot de passe : ${APP_USER_PASSWORD}

Variables d'environnement :
- JWT_SECRET : ${JWT_SECRET:0:20}...
- ANON_KEY : ${ANON_KEY:0:20}...
- SERVICE_ROLE_KEY : ${SERVICE_ROLE_KEY:0:20}...
- POSTGRES_PASSWORD : ${POSTGRES_PASSWORD}
EOF

if [ -n "$HUGGINGFACE_TOKEN" ]; then
    echo "- HUGGINGFACE_TOKEN : ${HUGGINGFACE_TOKEN:0:10}..." >> deployment-info.txt
fi

# Afficher le rÃ©sultat final
echo ""
echo "=========================================="
if [ "$DEPLOYMENT_OK" = true ]; then
    print_success "ğŸ‰ DÃ‰PLOIEMENT TERMINÃ‰ AVEC SUCCÃˆS !"
    echo ""
    echo "âœ… Tous les services sont opÃ©rationnels"
    echo "âœ… ${USERS_COUNT} utilisateur(s) crÃ©Ã©(s)"
    echo "âœ… ${PROFILES_COUNT} profil(s) crÃ©Ã©(s)"
    echo "âœ… ${BUCKETS_COUNT} bucket(s) crÃ©Ã©(s)"
else
    print_error "âš ï¸  DÃ‰PLOIEMENT TERMINÃ‰ AVEC DES PROBLÃˆMES"
    echo ""
    echo "Des erreurs ont Ã©tÃ© dÃ©tectÃ©es. Solutions possibles :"
    echo ""
    echo "1. Relancer le script de correction manuelle :"
    echo "   ./fix-complete-deployment.sh"
    echo ""
    echo "2. VÃ©rifier les logs des services problÃ©matiques :"
    echo "   docker logs antislash-talk-auth --tail 50"
    echo "   docker logs antislash-talk-storage --tail 50"
    echo ""
    echo "3. RedÃ©ployer complÃ¨tement depuis zÃ©ro :"
    echo "   ./clean-and-deploy.sh"
    echo ""
    echo "4. Diagnostic dÃ©taillÃ© de la base de donnÃ©es :"
    echo "   docker exec -it antislash-talk-db psql -U postgres -d postgres"
    echo "   Puis exÃ©cuter : \\dt auth.*"
    echo "                   \\dt storage.*"
    echo "                   \\dt public.*"
    echo ""
fi
echo "=========================================="
echo ""

exit $([ "$DEPLOYMENT_OK" = true ] && echo 0 || echo 1)
