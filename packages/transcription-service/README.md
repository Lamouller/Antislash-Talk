# üéôÔ∏è Service de Transcription PyTorch (OPTIONNEL)

Service **optionnel** de transcription avec Whisper V3 + diarisation PyTorch.

## ‚ö†Ô∏è Important : Ne remplace PAS les APIs existantes

Ce service **compl√®te** les APIs cloud (Gemini, OpenAI, Mistral) :
- ‚úÖ Les **cl√©s API** continuent de fonctionner normalement
- ‚úÖ C'est une **option suppl√©mentaire** "Local Server" dans les settings
- ‚úÖ **D√©sactivable** si non utilis√© (√©conomise ressources)

## üöÄ Activation

### Sans GPU (CPU uniquement)
```bash
# D√©marrer TOUS les services + PyTorch
docker-compose -f docker-compose.monorepo.yml --profile pytorch up -d

# Ou seulement le service PyTorch
docker-compose -f docker-compose.monorepo.yml up transcription-pytorch
```

### Avec GPU NVIDIA (recommand√© pour production)
1. Installer [NVIDIA Container Toolkit](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html)
2. D√©commenter la section `deploy` dans `docker-compose.monorepo.yml`
3. Lancer :
```bash
docker-compose -f docker-compose.monorepo.yml --profile pytorch up -d
```

## üìä V√©rification

```bash
# Status du service
curl http://localhost:8000/status

# Health check
curl http://localhost:8000/health
```

## üîß Configuration

### Token HuggingFace (pour diarisation)
Pour activer la diarisation (s√©paration des locuteurs) :

1. Cr√©er un compte sur [HuggingFace](https://huggingface.co)
2. Accepter les conditions de pyannote : https://huggingface.co/pyannote/speaker-diarization-3.1
3. Cr√©er un token : https://huggingface.co/settings/tokens
4. Ajouter dans `.env.local` :
```env
HUGGINGFACE_TOKEN=hf_xxxxxxxxxxxxxxxxxxxxx
```

**Sans token** : la transcription fonctionne, mais sans identification des locuteurs.

## üéØ Avantages vs API Cloud

| Crit√®re | PyTorch Local | API Cloud |
|---------|--------------|-----------|
| **Co√ªt** | Gratuit (apr√®s installation) | Payant par utilisation |
| **Confidentialit√©** | 100% local | Envoi vers serveurs tiers |
| **Vitesse (avec GPU)** | üöÄ Tr√®s rapide | D√©pend du r√©seau |
| **Mod√®les** | Whisper V3 complet | Selon provider |
| **Diarisation** | ‚úÖ pyannote 3.1 | Limit√© |
| **Hors ligne** | ‚úÖ Fonctionne | ‚ùå N√©cessite Internet |
| **Setup** | Plus complexe | Simple (juste cl√© API) |

## üì¶ Mod√®les disponibles

- `tiny` : 39M params, ~70MB, tr√®s rapide
- `base` : 74M params, ~140MB, rapide
- `small` : 244M params, ~470MB, bon compromis
- `medium` : 769M params, ~1.5GB, qualit√© √©lev√©e ‚≠ê **Recommand√©**
- `large-v2` : 1550M params, ~3GB, excellente qualit√©
- `large-v3` : 1550M params, ~3GB, meilleure version üèÜ

Le mod√®le se t√©l√©charge automatiquement au premier usage et est mis en cache.

## üîå API Endpoints

### POST /transcribe
Transcription d'un fichier audio

```bash
curl -X POST http://localhost:8000/transcribe \
  -F "file=@audio.mp3" \
  -F "language=fr" \
  -F "model=medium" \
  -F "enable_diarization=true"
```

R√©ponse :
```json
{
  "transcript": "Bonjour, c'est la transcription...",
  "language": "fr",
  "segments": [
    {"id": 0, "start": 0.0, "end": 2.5, "text": "Bonjour"}
  ],
  "speakers": [
    {"speaker": "SPEAKER_00", "start": 0.0, "end": 5.2}
  ],
  "model_used": "whisper-medium",
  "processing_time": 12.34
}
```

## üõë D√©sactivation

Si vous n'utilisez pas le service PyTorch :

```bash
# Arr√™ter uniquement PyTorch
docker-compose -f docker-compose.monorepo.yml stop transcription-pytorch

# Ou d√©marrer SANS le profil pytorch
docker-compose -f docker-compose.monorepo.yml up -d
```

Le service ne consomme alors **aucune ressource**.

## üìù Notes

- Premier d√©marrage : t√©l√©chargement des mod√®les (~5-10min selon connexion)
- Avec GPU : transcription 10-50x plus rapide
- Compatible Mac M1/M2 (via MPS), Linux GPU (CUDA), CPU partout

